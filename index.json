
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"","date":1686787200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1686787200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"Yao (John) Xu","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"http://yaoxu.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Yao (John) Xu"],"categories":["Learning notes"],"content":"Test-and-set based lock lock: unlock: ld R0, mem[addr] // load word into R0 cmp R0, #0 // compre R0 to 0 bnz lock // if nonzero jump to top st mem[addr], #1 st mem[addr], #0 // store 0 to address For a spinlock to work correctly and provide mutual exclusion, atomic operations are required. The atomicity of operations is necessary to prevent race conditions when multiple threads attempt to access and modify the lock variable simultaneously.\nlock: ts R0, mem[addr] // atomically load mem[addr] into R0 // if mem[addr] is 0 then mem[addr] to 1 cmp R0, #0 // if 0, lock obtained bnz lock\tunlock: st mem[addr], #0 // store 0 to address\tThis assembly code implements a simple spin lock mechanism, used to protect access to shared resources in a multi-threaded or multi-process environment. Let’s break down each line:\nlock: Label: This defines a label “lock”, which can be used for jumping to this location in the subsequent code.\nts R0, mem[addr]: This line performs a Test-and-Set operation. It loads the value from the memory address mem[addr] into register R0 and sets the value at mem[addr] to 1. This is an atomic operation that ensures mutual exclusion of lock access in a concurrent environment.\ncmp R0, #0: Compares the value in register R0 with 0.\nbnz lock: “bnz” stands for “branch if not zero.” It jumps to the “lock” label if the value in register R0 is not equal to 0. This creates a spin loop. If the value in mem[addr] is not 0, it means the lock is already acquired by another thread/process, and the current thread/process needs to wait for the lock to be released.\nst mem[addr], #0: This line stores the value 0 into the memory address mem[addr], effectively releasing the lock. Once a thread/process reaches this point, it indicates that it has finished its critical section and is ready to release the lock, allowing other threads/processes to acquire it.\nThere is a concern when multiple threads running on all cores simultaneously execute the ts (Test-and-Set) instruction. In doing so, they effectively attempt to perform write memory operations concurrently. As a consequence, this leads to a significant increase in busrdx (read and invalidate) events on the bus, resulting in bus contention and a substantial reduction in system efficiency. Source: http://15418.courses.cs.cmu.edu/spring2015content/lectures/16_synchronization/16_synchronization_slides.pdf\nTest-and-test-and-set lock void Lock(int* lock) { while (1) { while (*lock != 0); if (test_and_set(*lock) == 0) return; } } void Unlock(volatile int* lock) { *lock = 0; } // while another processor has the lock... // when lock is released, try to acquire it The Test-and-Test-and-Set (TTAS) mechanism has some distinctive characteristics compared to the standard Test-and-Set in certain scenarios. In the uncontended case, TTAS exhibits higher latency as it involves a two-step process: first, the processor must test the lock’s status, and then it performs the Test-and-Set operation if necessary.\nHowever, TTAS generates significantly less interconnect traffic compared to Test-and-Set. In the case of multiple waiting processors, TTAS results in only one invalidation per waiting processor per lock release, leading to O(P) invalidations. In contrast, Test-and-Set generates one invalidation per waiting processor per test, which can become more cumbersome when dealing with contention. This reduction in interconnect traffic makes TTAS more scalable, especially in scenarios with a high number of processors. The storage cost remains the same, requiring only a single integer variable for the lock.\nHowever, it’s important to note that TTAS still lacks provisions for fairness, meaning there is no inherent mechanism to ensure that waiting threads or processors acquire the lock in a fair order. As a result, certain threads may experience prolonged waiting times, leading to potential issues in highly concurrent environments.\nTicket lock struct lock { volatile int next_ticket; volatile int now_serving; }; void Lock(lock* l) { int my_ticket = atomic_increment(\u0026amp;l-\u0026gt;next_ticket); // take a \u0026#34;ticket\u0026#34; while (my_ticket != l-\u0026gt;now_serving); // wait for number to be called } void Unlock(lock* l) { l-\u0026gt;now_serving++; } struct lock: This defines a simple data structure named lock containing two volatile integer variables: next_ticket and now_serving. The next_ticket variable is used to issue tickets to waiting threads, while now_serving keeps track of the current ticket being served.\nvoid Lock(lock* l): This function implements the locking mechanism using the ticket lock approach. When a thread enters this function, it first takes a ticket by incrementing the next_ticket variable atomically. The thread then waits in a loop until its ticket number matches the value of now_serving, effectively waiting for its turn to access the critical section. This ensures that threads acquire the lock in the order they requested it, providing fairness.\nvoid Unlock(lock* l): This function is responsible for unlocking the …","date":1686787200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1686787200,"objectID":"a160f457bd6f88c637e041bfe1db21e1","permalink":"http://yaoxu.github.io/post/locks/","publishdate":"2023-06-15T00:00:00Z","relpermalink":"/post/locks/","section":"post","summary":"Learning notes about locking","tags":["Academic","Locks","Operating Systems","Learning notes"],"title":"About Locks","type":"post"},{"authors":["Yao (John) Xu"],"categories":["Learning notes"],"content":"Authors: A CS107 joint staff effort (Erik, Julie, Nate) x86-64 (also known as x64 and/or AMD64) is the 64-bit version of the x86/IA32 instruction set. Below is our overview of its features that are relevant to CS107. There is more extensive coverage on these topics in Chapter 3 of the B\u0026amp;O textbook. See also our x86-64 sheet for a compact reference.\nRegisters The table below lists the commonly used registers (sixteen general-purpose plus two special). Each register is 64 bits wide; the lower 32-, 16- and 8-bit portions are selectable by a pseudo-register name. Some registers are designated for a certain purpose, such as %rsp being used as the stack pointer or %rax for the return value from a function. Other registers are all-purpose, but have a conventional use depending on whether caller-owned or callee-owned. If the function binky calls winky, we refer to binky as the caller and winky as the callee. For example, the registers used for the first 6 arguments and return value are all callee-owned. The callee can freely use those registers, overwriting existing values without taking any precautions. If %rax holds a value the caller wants to retain, the caller must copy the value to a “safe” location before making a call. The callee-owned registers are ideal for scratch/temporary use by the callee. In contrast, if the callee intends to use a caller-owned register, it must first preserve its value and restore it before exiting the call. The caller-owned registers are used for local state of the caller that needs to preserved across further function calls.\nRegister Conventional Use Low 32-bits Low 16-bits Low 8-bits %rax Return value, callee-owned %eax %ax %al %rdi 1st argument, callee-owned %edi %di %dil %rsi 2nd argument, callee-owned %esi %si %sil %rdx 3rd argument, callee-owned %edx %dx %dl %rcx 4th argument, callee-owned %ecx %cx %cl %r8 5th argument, callee-owned %r8d %r8w %r8b %r9 6th argument, callee-owned %r9d %r9w %r9b %r10 Scratch/temporary, callee-owned %r10d %r10w %r10b %r11 Scratch/temporary, callee-owned %r11d %r11w %r11b %rsp Stack pointer, caller-owned %esp %sp %spl %rbx Local variable, caller-owned %ebx %bx %bl %rbp Local variable, caller-owned %ebp %bp %bpl %r12 Local variable, caller-owned %r12d %r12w %r12b %r13 Local variable, caller-owned %r13d %r13w %r13b %r14 Local variable, caller-owned %r14d %r14w %r14b %r15 Local variable, caller-owned %r15d %r15w %r15b %rip Instruction pointer %eflags Status/condition code bits Addressing Modes True to its CISC nature, x86-64 supports a variety of addressing modes. An addressing mode is an expression that calculates an address in memory to be read/written to. These expressions are used as the source or destination for a mov instruction and other instructions that access memory. The code below demonstrates how to write the immediate value 1 to various memory locations in an example of each of the available addressing modes:\nmovl $1, 0x604892 # direct (address is constant value) movl $1, (%rax) # indirect (address is in register %rax) movl $1, -24(%rbp) # indirect with displacement # (address = base %rbp + displacement -24) movl $1, 8(%rsp, %rdi, 4) # indirect with displacement and scaled-index # (address = base %rsp + displ 8 + index %rdi * scale 4) movl $1, (%rax, %rcx, 8) # (special case scaled-index, displ assumed 0) movl $1, 0x8(, %rdx, 4) # (special case scaled -index, base assumed 0) movl $1, 0x4(%rax, %rcx) # (special case scaled-index, scale assumed 1) Common Instructions A note about instruction suffixes: many instructions have a suffix (b, w, l, or q) which indicates the bitwidth of the operation (1, 2, 4, or 8 bytes, respectively). The suffix is often elided when the bitwidth can be determined from the operands. For example, if the destination register is %eax, it must be 4 bytes, if %ax it must be 2 bytes, and %al would be 1 byte. A few instructions such as movs and movz have two suffixes: the first is for the source operand, the second for the destination. For example, movzbl moves a 1-byte source value to a 4-byte destination.\nWhen the destination is a sub-register, only those specific bytes in the sub-register are written with one broad exception: a 32-bit instruction zeroes the high-order 32 bits of the destination register.\nadd src, dst: dst += src sub src, dst: dst -= src imul src, dst: dst *= src neg dst: dst = -dst (arithmetic inverse) and src, dst: dst \u0026amp;= src or src, dst: dst |= src xor src, dst: dst ^= src not dst: dst = ~dst (bitwise inverse) shl count, dst: dst «= count (left shift dst by count positions), synonym sal sar count, dst: dst »= count (arithmetic right shift dst by count positions) shr count, dst: dst »= count (logical right shift dst by count positions) Some instructions have special-case variants with different numbers of operands:\nimul src: single operand imul assumes the other operand is in %rax, computes 128-bit result, stores high 64-bits in %rdx, low 64-bits in %rax shl dst: dst «= 1 (no count =\u0026gt; assume 1, same …","date":1686787200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1686787200,"objectID":"3e4e500ac33efcde1bc119708162080a","permalink":"http://yaoxu.github.io/post/x86_notes/","publishdate":"2023-06-15T00:00:00Z","relpermalink":"/post/x86_notes/","section":"post","summary":"Learning notes about x86","tags":["Academic","x86","Learning notes"],"title":"x86 Notes","type":"post"},{"authors":["Yao (John) Xu"],"categories":["Learning notes"],"content":"POSIX threads Pthreads (POSIX Threads) is a standard interface for manipulating threads in C programs. It provides a set of around 60 functions that allow developers to create, manage, and synchronize threads.\nThreads in Pthreads run thread routines, which are defined as functions with the following signature:\nvoid *threadroutine(void *vargp); Some of the key functions provided by Pthreads include:\nCreating and reaping threads:\npthread_create(pthread_t *tid, ..., func *f, void *arg): Creates a new thread that executes the function f with the argument arg. pthread_join(pthread_t tid, void **thread_return): Waits for the thread with the specified thread ID (tid) to terminate and retrieves its exit status. Determining the thread ID:\npthread_self(): Returns the thread ID of the calling thread. Terminating threads:\npthread_cancel(pthread_t tid): Requests cancellation of the thread with the specified thread ID (tid). pthread_exit(void *thread_return): Terminates the calling thread and returns a value to the joining thread. Using return in the primary thread routine also terminates the thread. Note that calling exit() will terminate all threads in the process. Synchronizing access to shared variables:\nPthreads provides synchronization primitives such as mutexes, condition variables, and barriers to coordinate access to shared variables and ensure thread safety. Functions like pthread_mutex_init, pthread_mutex_lock, pthread_mutex_unlock, pthread_cond_init, pthread_cond_wait, pthread_cond_signal, etc., are used for synchronization purposes. Classic Problems Producer-consumer problem #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; #include \u0026lt;semaphore.h\u0026gt; sem_t empty, full; // Define global semaphores empty and full pthread_mutex_t mutex; // Define a global mutex for different functions int buffer_count = 0; // Define a global variable to represent the number of products in the buffer void *producer(void *arg); // Producer thread void *consumer(void *arg); // Consumer thread int main(int argc, char *argv[]) { pthread_t thrd_prod, thrd_cons; pthread_mutex_init(\u0026amp;mutex, NULL); // Initialize the mutex sem_init(\u0026amp;empty, 0, 5); // Initialize the empty semaphore sem_init(\u0026amp;full, 0, 0); // Initialize the full semaphore // Create producer and consumer threads if (pthread_create(\u0026amp;thrd_prod, NULL, producer, NULL) != 0) printf(\u0026#34;Thread creation failed.\u0026#34;); if (pthread_create(\u0026amp;thrd_cons, NULL, consumer, NULL) != 0) printf(\u0026#34;Thread creation failed.\u0026#34;); // Wait for threads to finish if (pthread_join(thrd_prod, NULL) != 0) printf(\u0026#34;Waiting for thread failed.\u0026#34;); if (pthread_join(thrd_cons, NULL) != 0) printf(\u0026#34;Waiting for thread failed.\u0026#34;); sem_destroy(\u0026amp;full); // Release the semaphore sem_destroy(\u0026amp;empty); // Release the semaphore pthread_mutex_destroy(\u0026amp;mutex); // Destroy the mutex return 0; } void *producer(void *arg) { while (1) { sem_wait(\u0026amp;empty); // empty-1 pthread_mutex_lock(\u0026amp;mutex); // Lock the mutex // Successfully acquired the mutex, now can perform production printf(\u0026#34;Producer puts a product in the buffer.\u0026#34;); buffer_count++; printf(\u0026#34;The buffer count is %d\\n\u0026#34;, buffer_count); pthread_mutex_unlock(\u0026amp;mutex); // Unlock the mutex sem_post(\u0026amp;full); // full+1 } } void *consumer(void *arg) { while (1) { sem_wait(\u0026amp;full); // full-1 pthread_mutex_lock(\u0026amp;mutex); // Lock the mutex // Successfully acquired the mutex, now can perform consumption printf(\u0026#34;Consumer gets a product from the buffer.\u0026#34;); buffer_count--; printf(\u0026#34;The buffer count is %d\\n\u0026#34;, buffer_count); pthread_mutex_unlock(\u0026amp;mutex); // Unlock the mutex sem_post(\u0026amp;empty); // empty+1 } } Readers–writers problem The first readers-writers problem, which favors readers, can be summarized with the following conditions:\nNo reader should be kept waiting unless a writer has already been granted permission to use the shared object. If a writer is already waiting, a reader that arrives should be given priority over the writer. #include \u0026lt;pthread.h\u0026gt; #include \u0026lt;semaphore.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; sem_t wrt; pthread_mutex_t mutex; int cnt = 1; int numreader = 0; void *writer(void *wno) { sem_wait(\u0026amp;wrt); cnt = cnt*2; printf(\u0026#34;Writer %d modified cnt to %d\\n\u0026#34;,(*((int *)wno)),cnt); sem_post(\u0026amp;wrt); } void *reader(void *rno) { // Reader acquire the lock before modifying numreader pthread_mutex_lock(\u0026amp;mutex); numreader++; if(numreader == 1) { sem_wait(\u0026amp;wrt); // If this id the first reader, then it will block the writer } pthread_mutex_unlock(\u0026amp;mutex); // Reading Section printf(\u0026#34;Reader %d: read cnt as %d\\n\u0026#34;,*((int *)rno),cnt); // Reader acquire the lock before modifying numreader pthread_mutex_lock(\u0026amp;mutex); numreader--; if(numreader == 0) { sem_post(\u0026amp;wrt); // If this is the last reader, it will wake up the writer. } pthread_mutex_unlock(\u0026amp;mutex); } int main(){ pthread_t read[10],write[5]; pthread_mutex_init(\u0026amp;mutex, NULL); sem_init(\u0026amp;wrt,0,1); int a[10] = {1,2,3,4,5,6,7,8,9,10}; //Just used for numbering the producer and consumer for(int i = 0; i \u0026lt; 10; i++) { pthread_create(\u0026amp;read[i], NULL, (void *)reader, (void *)\u0026amp;a[i]); } for(int i = 0; i …","date":1685404800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1685404800,"objectID":"af254c5828af54b7546b35540d6b027b","permalink":"http://yaoxu.github.io/post/com/","publishdate":"2023-05-30T00:00:00Z","relpermalink":"/post/com/","section":"post","summary":"Learning notes about parallel programming technologies","tags":["Academic","Learning notes"],"title":"POSIX threads, CUDA, OpenMP and MPI","type":"post"},{"authors":["Yao (John) Xu"],"categories":["Operating System"],"content":"Repo Link https://github.com/YaoGH-code/OS\nentry.S As per the specifications mentioned in the linker script, the RAM in the system begins at the physical address 0x80000000. It has a total size of 128 megabytes (128M). The specific memory layout is determined by the way QEMU simulates the memory in the system.\nOnce the boot loader successfully loads the kernel into the RAM, the execution of the system starts from the entry.S file. This file serves as the entry point of the kernel code.\n.section .text .global _entry _entry: /* basically adding a offset ((mhartid+1)*4096) to find the starting address of each hart */ la sp, stack0 # load the address of symbol stack0 to sp register li a0, 4096 # load the immediate to a0 register /* csrr: Control and Status Register Read The mhartid CSR is an XLEN-bit read-only register containing the integer ID of the hardware thread running the code. This register must be readable in any implementation. Hart IDs might not necessarily be numbered contiguously in a multiprocessor system, but at least one hart must have a hart ID of zero. mhartid -\u0026gt; Machine Hart ID -\u0026gt; to identify currently running thread Hart -\u0026gt; Hardware Thread */ csrr a1, mhartid addi a1, a1, 1 # a1 += 1 mul a0, a0, a1 # a0 *= a1 add sp, sp, a0 # sp += a0 call start # go to start in start.c The purpose of the code snippet is to load the address of an initial stack for each core into the sp (stack pointer) register. This allows for a smooth transition to the C code in the start.c file. In start.c, the stack is defined as an array, and each core can utilize a portion of this array as its stack.\nAbout Spin Lock A spinlock is a commonly used synchronization mechanism in operating systems and concurrent programming, with the primary objective to prevent multiple threads or processes from accessing or modifying shared resources simultaneously, thereby causing data inconsistency or race conditions. The basic working principle of a spinlock is that if the lock is already occupied, a thread attempting to acquire the lock will “spin” in a loop until the lock becomes available.\nA distinguishing characteristic of spinlocks, as compared to other types of locks (such as mutexes), is that they do not put the thread into a sleeping state. When a thread cannot acquire a spinlock, it continues running and repeatedly checks the lock’s status instead of being suspended and yielding the CPU to other threads. This makes spinlocks particularly suited for scenarios where the lock holding time is short but needs to be acquired and released quickly. However, spinlocks are not a panacea. Spinning while waiting for the lock to be released consumes CPU resources, and if the lock is held for a long time, this could lead to resource wastage. Thus, understanding when and how to use spinlocks is crucial for efficient concurrency control.\nIn the first code snippet:\nif (*lock == 0) *lock = 1; else try again; This simplistic lock acquisition approach does not consider the complexities introduced by multithreading, either within a single core or across multiple cores. In such environments, multiple threads could concurrently read the lock as being available (*lock == 0) and proceed to acquire it, leading to a race condition where multiple threads think they have exclusive access to the lock.\nTo address these concurrency issues, we need to ensure that the check and set operations are atomic, meaning they appear to occur instantaneously and cannot be interrupted. In RISC-V, one way to achieve atomicity is by using the AMOSWAP instruction for an atomic swap operation.\nConsider this revised approach using Compare and Swap (CAS):\n/* CAS */ while(__sync_lock_test_and_set(\u0026amp;lock-\u0026gt;locked, 1) != 0); In this operation, we are attempting to atomically set lock-\u0026gt;locked to 1 and retrieve its old value in one go. If the previous value is not zero, which indicates the lock is currently held by another thread, we continue spinning and attempt the operation again.\nAn essential addition here is the memory fence, which is employed to prevent the C compiler or the hardware from reordering memory access instructions in a way that could lead to inconsistencies. This reordering is often done for optimization purposes but can lead to problems in a multithreaded context, especially with locks. By placing a memory fence after acquiring the lock, we ensure that no memory operations that occur after the lock acquisition are mistakenly executed beforehand. Consequently, this preserves the integrity of the data protected by the lock and prevents potential race conditions.\nvoid intr_push(){ /* Read current sstatus */ uint64_t cur_sstatus = read_sstatus(); /* If SIE, old_state = 1; if not SIE, old_state = 0 */ int old_state = ((cur_sstatus \u0026amp; SSTATUS_SIE) != 0); /* Turn off interrupt */ write_sstatus(read_sstatus() \u0026amp; ~SSTATUS_SIE); /* If in first level of interrupt, store current intrrupt state */ if(!get_mycore()-\u0026gt;disable_cnt) get_mycore()-\u0026gt;prev_int_state = old_state; /* Disable …","date":1682985600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682985600,"objectID":"1fe1424980ed6c7a61df434bbd09918d","permalink":"http://yaoxu.github.io/post/os/","publishdate":"2023-05-02T00:00:00Z","relpermalink":"/post/os/","section":"post","summary":"Implementation notes of the OS","tags":["Academic","Open Source"],"title":"RISC-V OS Kernel Rewrite Based on MIT Xv6","type":"post"},{"authors":["Yao (John) Xu"],"categories":["Operating System","Parallel Computing"],"content":"Repo Link Overview This project aims to provide a robust preemptive user-level thread library that simplifies the creation and management of user-level threads. By utilizing interfaces such as “uthread_create” and “uthread_join,” users familiar with POSIX threads can easily develop programs with user-level parallelism. The context of user-level threads in this project is implemented through a combination of our custom “uthread” data structure and the “ucontext” functionality provided by POSIX. Additionally, a lock-free data structure is employed to maintain each worker thread efficiently. The scheduling of user threads relies heavily on signals in this project. When a signal arrives, it indicates the start of the next scheduling round for each worker thread. The stack prepared by the kernel for the signal handler is crucial for smooth context switching. To ensure thread safety at the user level, interfaces such as “umalloc,” “uprintf,” and “uthread_mutex_lock” are provided. These interfaces facilitate safe memory allocation, printing, and mutual exclusion. This thread library is compatible with machines running MacOS or Linux with x86 architecture CPUs. Extensive testing has been conducted to verify the correctness and scalability of the system.\nBackground With the increasing prevalence of multi-core processors, high-performance computing demands, scalability requirements, user expectations for responsiveness, and cost-efficiency considerations, concurrent programming has become increasingly essential. To achieve concurrency, multi-threading has emerged as a popular approach, primarily due to its ability to leverage the shared memory model and its lower resource consumption. POSIX threads (pthreads) have gained widespread adoption for multi-threading implementations due to their efficiency, scalability, reliability, and broad support across various operating systems. However, effectively harnessing pthreads for efficient concurrency still presents significant challenges.\nOne challenge arises when the number of concurrent tasks increases, potentially causing significant scheduling overhead and overwhelming hardware resources. The thread pool technique has long been used to address this issue, where it abstracts each concurrent task into a unit of work and adds it to a shared work queue. From this queue, threads in the pool grab one unit of work and finish executing it, then proceed to the next until the queue is empty. The thread pool can be a neat solution to deal with a huge quantity of tasks while keeping the scheduling overhead bounded. However, it may be insufficient when the running spans of each concurrent task are highly variable. This is especially true if we aim to achieve user-level multitasking, where we can have long-running or persistent tasks. The thread pool may not be a wise solution here, as the tasks that run much longer than the others can cause drastic delay to those far down in the queue, which, in the worst case, may never be executed. That’s because in the thread pool model subsequent tasks are not executed until all preceding tasks have been completed. If we were still to use pthreads naively, we would end up spawning hundreds of threads again, one for each task, producing immense overhead and hurting performance.\nClearly, the thread pool model should be preserved. But how to break the execution of long-running blocking tasks without compromising correctness to allow other tasks to run? To answer this question, we must introduce the idea of user-level threads. In this project, we turn each unit of work in the work queue into an execution context. Each worker thread (POSIX thread) has a task queue stores user level tasks that assigned to it when user create a user level thread with uthread create. These user level tasks are structures where we turn each unit of work in the work queue (we are still sticking to the thread pool model) into an execution context, keeping track of the full state of each concurrently running task, and instead of mapping one task to one dedicated POSIX thread, we dynamically decide which POSIX thread in the pool should execute which task, so that we can safely break the execution of one task, saving its context back to the shared queue, and start the execution of the next user-level thread, loading the corresponding context from the queue.\nApproach Before going into the core part of this project, some initialization and helper function will be introduced first. This user level thread library requires some initialization before starting to create and schedule user level threads. The runtime start function shown below is the first function will be called to initialize a structure called runtime which is defined in uthread.c file that contains some run time information. First, there will be only one thread enter this function. We record this main thread as the master worker thread (pthread) and mark the start flag to one so that the runtime will only be …","date":1682899200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682899200,"objectID":"8b3621a7d9b5f8e4e83360edae723b4f","permalink":"http://yaoxu.github.io/post/uthread/","publishdate":"2023-05-01T00:00:00Z","relpermalink":"/post/uthread/","section":"post","summary":"CMU 15-618 Parallel Computer Architecture and Programming final project","tags":["Academic","Open Source"],"title":"A Preemptive User-Level Thread Library","type":"post"},{"authors":["Yao (John) Xu"],"categories":["Learning notes"],"content":"1. Two Sum Given an array of integers nums and an integer target, return indices of the two numbers such that they add up to target. You may assume that each input would have exactly one solution, and you may not use the same element twice.\n/* Solution: Loop through all elements in the nums array. If the number we want is in the hash map, then we return the val(index) of the key(target-nums[i]) and the current index. Otherwise, we add that key-val into the hash map. Finally, there is no such number in the array, return empty array. */ class Solution { public: vector\u0026lt;int\u0026gt; twoSum(vector\u0026lt;int\u0026gt;\u0026amp; nums, int target) { unordered_map\u0026lt;int,int\u0026gt; M; for(int i=0; i\u0026lt;nums.size(); i++){ if (M.count(target-nums[i])) return {i, M[target-nums[i]]}; else M[nums[i]] = i; } return {}; } }; 2. Add Two Numbers You are given two non-empty linked lists representing two non-negative integers. The digits are stored in reverse order, and each of their nodes contains a single digit. Add the two numbers and return the sum as a linked list. You may assume the two numbers do not contain any leading zero, except the number 0 itself. ex: 2-\u0026gt;4-\u0026gt;3 5-\u0026gt;6-\u0026gt;4 7-\u0026gt;0-\u0026gt;8 /* Solution: We have two linked lists for two numbers. We loop through two linked lists in the while loop and compute a temp sum for each digit (also include the carry) and add new node which representing a digit in the new number to the output linked list. Also, updates the carry for the next iteration. */ /** * Definition for singly-linked list. * struct ListNode { * int val; * ListNode *next; * ListNode() : val(0), next(nullptr) {} * ListNode(int x) : val(x), next(nullptr) {} * ListNode(int x, ListNode *next) : val(x), next(next) {} * }; */ class Solution { public: ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) { ListNode* dummy_head = new ListNode(-1); ListNode* current = dummy_head; int carry=0; while(l1 || l2 || carry){ int sum=0; if(l1){ sum += l1-\u0026gt;val; l1 = l1-\u0026gt;next; } if(l2){ sum += l2-\u0026gt;val; l2 = l2-\u0026gt;next; } sum += carry; ListNode* node = new ListNode(sum%10); carry = sum/10; current-\u0026gt;next = node; current = current-\u0026gt;next; } return dummy_head-\u0026gt;next; } }; 3. Longest Substring Without Repeating Characters Given a string s, find the length of the longest substring without repeating characters.\n/* Solution: The key point is to correctly kepp track of the left pointer. If we do not use max(left, M[s[i]]+1), we might cover a string with repeated char that we have identiftied before (ex. abba) which is wrong so we cannot let left pointer goes backward to cover substring with potential repeated char. */ //we cannot move the left back //abba class Solution { public: int lengthOfLongestSubstring(string s) { if (!s.size()) return 0; unordered_map\u0026lt;char, int\u0026gt; m; int max_len = 1; int left = 0; for (int i=0; i\u0026lt;s.length(); i++){ if (m.count(s[i])){ left = max(left, m[s[i]]+1); } m[s[i]] = i; max_len = max(max_len, i-left+1); } return max_len; } }; 5. Longest Palindromic Substring Given a string s, return the longest palindromic substring in s.\n/* Solution: helper function: expand from a \u0026#34;pivot\u0026#34; to both sides and try to find the longest palindromic substring. There are two cases: substring with odd number of chars and substring with even number of chars. If the new substring is longer, update the starting point and length. */ class Solution { public: int helper(int l, int r, string s){ while(l\u0026gt;=0 \u0026amp;\u0026amp; r\u0026lt;s.length() \u0026amp;\u0026amp; s[l]==s[r]){ l--; r++; } return r-l-1; } string longestPalindrome(string s) { int n=s.length(); int len=0; int start=0; for (int i=0; i\u0026lt;n; i++){ int cur = max(helper(i,i,s), helper(i,i+1,s)); if (cur\u0026gt;len){ len=cur; start = i-(len-1)/2; } } return s.substr(start,len); } }; 6. Zigzag Conversion The string “PAYPALISHIRING” is written in a zigzag pattern on a given number of rows like this: (you may want to display this pattern in a fixed font for better legibility) P A H N A P L S I I G Y I R And then read line by line: “PAHNAPLSIIGYIR”\n/* Solution: Prepare n strings and fill them with different levels. For example, level 0,1,2... if we reached the lowest or highest level, change the direction. Finally, put all level of strings together. */ class Solution { public: string convert(string s, int n) { if(n==1) return s; vector\u0026lt;string\u0026gt; v(n); int level = 0; int dir = 1; string res; for (int i=0; i\u0026lt;s.length(); i++){ v[level]+=s[i]; if (dir) level++; else level--; if (level == n-1) dir=0; if (level == 0) dir=1; } for (string s:v) res+=s; return res; } }; 7. Reverse Integer Given a signed 32-bit integer x, return x with its digits reversed. If reversing x causes the value to go outside the signed 32-bit integer range [-231, 231 - 1], then return 0.\nclass Solution { public: int reverse(int x) { long long res = 0; while(x) { res = res*10 + x%10; x /= 10; } return (res\u0026lt;INT_MIN || res\u0026gt;INT_MAX) ? 0 : res; } }; 9. Palindrome Number Given an integer x, return true if x is a palindrome, and false otherwise.\nclass Solution { public: bool isPalindrome(int x) { if( x\u0026lt;0 || ( x % 10==0 \u0026amp;\u0026amp; x!=0)) return …","date":1682848800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682848800,"objectID":"e38d3482014a56edb2e5a7d9b068c7ba","permalink":"http://yaoxu.github.io/post/leetcode/","publishdate":"2023-04-30T10:00:00Z","relpermalink":"/post/leetcode/","section":"post","summary":"Learning notes about Leetcode Questions","tags":["Academic","Learning notes"],"title":"Data Structures and Algorithms (C++)","type":"post"},{"authors":["Yao (John) Xu"],"categories":["Operating System","C Programming"],"content":"Repo Link: https://github.com/YaoGH-code/MemSim\n","date":1682820000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682820000,"objectID":"a6dbda7f61dfb17a4832099b9de27242","permalink":"http://yaoxu.github.io/post/vmp_sim/","publishdate":"2023-04-30T02:00:00Z","relpermalink":"/post/vmp_sim/","section":"post","summary":"The C implementation of a virtual memory and process scheduling simulator","tags":["Academic","Open Source"],"title":"A Simulator of Virtual Memory and Process Scheduling","type":"post"},{"authors":["Yao (John) Xu"],"categories":["CPU design","Computer Architecture","Verilog"],"content":"Repo Link https://github.com/YaoGH-code/mCPU\nIntroduction The MIPS (Microprocessor without Interlocked Pipeline Stages) architecture is a reduced instruction set computer (RISC) architecture that has played a significant role in the development of microprocessors. MIPS architecture features a clean and streamlined instruction set, emphasizing simplicity and efficiency. It focuses on optimizing the performance of frequently used instructions, making it suitable for a wide range of applications, including embedded systems, consumer electronics, networking equipment, and high-performance computing.\nOne of the distinguishing characteristics of MIPS is its fixed instruction format, where instructions are encoded in a 32-bit word. This fixed-format allows for efficient decoding and pipelining, enabling high-performance execution and reducing the complexity of the microarchitecture. MIPS processors employ a five-stage pipeline, including instruction fetch, instruction decode, execution, memory access, and write-back. This pipelining technique enables instructions to be processed concurrently, maximizing the overall throughput of the processor.\nDesign The picture above shows the structure and components of this CPU. This CPU is composed of 5 stages, which are: Instruction Fetch(IF), Instruction Decode(ID), Execution(EXE), Memory(MEM) and Write Back(WB) stage.\nIF Stage The Instruction Fetch stage consists of three components. Firstly, there is the program counter register, which holds the physical address of the next instruction in the instruction memory (represented here as a simplified memory structure). In each cycle, an adder increments the address by 4, and the resulting address is stored in the program counter for the next clock cycle. Simultaneously, the instruction memory, equipped with an input port and an output port, fetches an instruction using the address from the program counter. This fetched instruction is then stored in the IF/ID register during the same cycle.\nID Stage In the instruction decoding stage, we can clearly see the connection between the instruction set and the actual electronic circuit. First, the instruction will be decoded into following components:\nop code: basic operation of the instruction rs: the first register source operand rt: the second register source operand rd: the register destination operand shamt: shift amount to be used in shift instructions funct code: function code imm: immediate value Combining the Op code (bits 31-26) and funct code (bits 5-0) in MIPS instructions enables the hardware to determine the current instruction and its corresponding function. For example, instructions for basic arithmetic operation(R-format) have the same op code 0x0 but with a different funct code. So, Op code and funct code combined will be provided to the control unit for generating control signals for later stages. These control signals will be covered later.\nThere is also a MUX in the MIPS architecture that utilizes the control signal “regrt” to select either the “rd” or “rt” register. The selected signal, along with the data to be written back to the register file, is then passed back to the ID stage. This MUX serves the purpose of determining the appropriate destination for the write-back operation. For instance, instructions with an opcode of 0 will select the “rd” register as the destination. On the other hand, for the LW (Load Word) instruction, the data retrieved from the data memory during the MEM stage will be written back to the register specified by the “rt” register. Therefore, the MUX helps decide which part of the instruction contains the desired destination for the write-back operation.\nThe signals “rs” and “rt” are used to access the register file and read the data stored in registers “rs” and “rt” simultaneously through the “qa” and “qb” ports. Additionally, the immediate value (imm) is sign extended and passed to the ALU for computation. This computation takes place during the EXE stage, where the ALU performs operations using the immediate value and other relevant data.\nThen, let’s look at the control signals generated by the control unit:\nwreg: A write back to register will happen in the lifecycle of the current instruction m2reg: A write back to register with data in memory will happen in the lifecycle of the current instruction wmem: A write to memory will happen in the lifecycle of the current instruction aluc: ALU operation mode ex. if aluc==b0010, then ALU_out \u0026lt;= ALU_a + ALU_b; aluimm: A immediate value is needed by the ALU to finish this operation EXE Stage In the EXE (Execute) stage, two signals are employed to control the ALU’s input sources and operation mode. Firstly, the “ealuc” signal is utilized to select the desired operation mode for the ALU. For instance, a value of “b0010” would indicate that the ALU should perform an addition operation on its two input numbers.\nSecondly, the “ealuimm” signal determines the source of the input port “b” of the ALU. …","date":1682812800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682812800,"objectID":"e4519e50a6915a7d300d74618bf3a90a","permalink":"http://yaoxu.github.io/post/mcpu/","publishdate":"2023-04-30T00:00:00Z","relpermalink":"/post/mcpu/","section":"post","summary":"A 5-stage pipeline MIPS CPU implemented in Verilog","tags":["Academic","Open Source"],"title":"A 5-stage pipeline MIPS CPU","type":"post"},{"authors":["Yao (John) Xu"],"categories":["Learning notes"],"content":"Overview When multiple CPU cores are added to a system, each with its own cache, the problem of maintaining cache coherence arises. Cache coherence refers to the consistency of data stored in different caches that are supposed to reflect the same memory location. In other words, if one core modifies data that is also present in another core’s cache, the caches need to be synchronized to ensure data integrity.Without cache coherence protocols, the caches would operate independently, and modifications made by one core may not be immediately visible to other cores. This lack of synchronization can lead to data inconsistencies and errors in a shared memory system.\nTo address this issue, cache coherency protocols are employed. These protocols ensure that all caches observe a consistent view of memory. They coordinate cache operations, such as reading and writing data, and enforce a set of rules for maintaining cache coherence. One common approach is to have a shared cache hierarchy, where all cores share a common cache level, such as the L1 cache. In this case, all memory operations from different cores go through the shared cache, which acts as a central point for maintaining coherence. However, this approach can introduce bottlenecks and performance limitations due to contention for the shared cache’s resources. Cache coherency protocols aim to strike a balance between maintaining data consistency and maximizing performance. These protocols use various techniques such as invalidation and sharing of cache lines, snooping, and message passing between caches to ensure that data modifications made by one core are propagated to other caches in a timely and efficient manner. By implementing cache coherency protocols, multi-core systems can achieve the benefits of parallel processing while maintaining the illusion of a single shared memory system.\nSnooping-based cache coherence MSI In the MSI (Modified, Shared, Invalid) cache coherence protocol, each cache line can have one of three possible states:\nModified: The line has been modified in the cache. It is only valid in one cache.\nShared: The line is valid in one or more caches. (multiple caches are sharing the data legally)\nInvalid: The line is either not present in the current cache or has been invalidated by a bus request.\nMSI state graph: Wikipedia: https://en.wikipedia.org/wiki/MSI_protocol\nThe two diagrams above provide a clear explanation of how MSI operates. When a cache line is in the invalid state, the CPU can perform read or write operations. When the CPU reads data from a specific address, a Bus Read signal is generated on the bus. The cache line then obtains the most recent data and may potentially share this data with other caches. This clearly represents a state of data “sharing”. This operation does not affect the data in other caches; they simply friendly share the data.\nWhat happens when the CPU performs a write operation to a specific address? In this case, a Bus Write signal (BusRdx) is generated on the bus. When other cache controllers on the bus, which are monitoring the bus, detect an attempt to modify the data corresponding to the address in the write operation, they realize that their cached data is no longer or soon will no longer be the most up-to-date. They change the state of the cache line to invalid, indicating that the exclusive right to modify the data belongs to a cache other than the one that observed the BusRdx signal.\nFor a cache line in the Shared state, when the CPU performs a write operation to this cache line, it still appears as a cache hit, and a Bus Read signal is generated on the bus. This allows the cache line to obtain the most up-to-date data from the bus and continue sharing it with other caches.\nSimilarly, if the CPU attempts to write to a cache line in the Shared state, the cache line still needs to acquire exclusive write permission. It achieves this by generating a Bus Write signal (BusRdx) on the bus. This signal notifies other caches that the cache line’s data will be modified exclusively by the cache generating the BusRdx signal. Other caches observing this signal will transition the corresponding cache line to the Invalid state to maintain cache coherence and ensure that only one cache has the right to modify the data.\nIndeed, for a cache line in the Modified (M) state, when it receives a BusRd (Bus Read) or BusRdX (Bus Read Exclusive) signal on the bus, the cache line’s data needs to be flushed (written back) to memory. This ensures that other CPUs or caches can obtain the most up-to-date data from memory.\nWhen a cache line is in the Modified state and a BusRd signal is observed on the bus, it indicates that another CPU or cache wants to read the data from that address. Since the cache line in the Modified state has the most recent data, it needs to write the data back to memory so that the requesting CPU or cache can obtain the updated value.\nSimilarly, when a cache line is in the Modified state and a BusRdX …","date":1682726400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682726400,"objectID":"2b27e310bbbc83a014d0645874b42a14","permalink":"http://yaoxu.github.io/post/cache/","publishdate":"2023-04-29T00:00:00Z","relpermalink":"/post/cache/","section":"post","summary":"Learning notes about cache coherence","tags":["Academic","Learning notes"],"title":"About Cache Coherence","type":"post"},{"authors":["Yao (John) Xu"],"categories":["Learning notes"],"content":" 1. Introduction The make utility automatically determines which pieces of a large program need to be recompiled, and issues commands to recompile them. You need a file called a makefile to tell make what to do. Most often, the makefile tells make how to compile and link a program.\nSyntax A Makefile contains some rules with the following shape:\ntarget … : prerequisites … recipe … … A target is usually the name of a file that is generated by a program; examples of targets are executable or object files. A target can also be the name of an action to carry out, such as ‘clean’. The prerequisites are also file names, separated by spaces. These files need to exist before the commands for the target are run. These are also called dependencies. The commands are a series of steps typically used to make the target(s). These need to start with a tab character, not spaces. Here is a typical Makefile - one that compiles a single C file:\ntest: cc test.c -o test We can simply running make. Since there’s no target supplied as an argument to the make command, the first target is run. In this case, there’s only one target (test). The first time you run this, test will be created. The second time, you’ll see make: ’test’ is up to date. That’s because the test file already exists. But there’s a problem: if we modify test.c and then run make, nothing gets recompiled.\nInstead, we can do this:\ntest: test.c cc test.c -o test When we run make again, the following set of steps happens:\nThe first target is selected, because the first target is the default target This has a prerequisite of test.c Make decides if it should run the test target. It will only run if test doesn’t exist, or test.c is newer than test. Here is a more complicated example:\nedit : main.o kbd.o command.o display.o \\ insert.o search.o files.o utils.o cc -o edit main.o kbd.o command.o display.o \\ insert.o search.o files.o utils.o main.o : main.c defs.h cc -c main.c kbd.o : kbd.c defs.h command.h cc -c kbd.c command.o : command.c defs.h command.h cc -c command.c display.o : display.c defs.h buffer.h cc -c display.c insert.o : insert.c defs.h buffer.h cc -c insert.c search.o : search.c defs.h buffer.h cc -c search.c files.o : files.c defs.h buffer.h command.h cc -c files.c utils.o : utils.c defs.h cc -c utils.c clean : rm edit main.o kbd.o command.o display.o \\ insert.o search.o files.o utils.o Edit is a target that requires eight prerequisites. The command is to compile executable file “edit” with eight object files. Each of the object file requires some C files and header files. We do not need to include header file name in the command since it is already included in the C file and the purpose to include header files in the prerequisites is to make sure the file is already there, just like a additional verification.\nWhen a target is a file, it needs to be recompiled or relinked if any of its prerequisites change. In addition, any prerequisites that are themselves automatically generated should be updated first. In this example, edit depends on each of the eight object files; the object file main.o depends on the source file main.c and on the header file defs.h.\nMake clean The target ‘clean’ is not a file, but merely the name of an action. Since you normally do not want to carry out the actions in this rule, ‘clean’ is not a prerequisite of any other rule. Consequently, make never does anything with it unless you tell it specifically. Note that this rule not only is not a prerequisite, it also does not have any prerequisites, so the only purpose of the rule is to run the specified recipe. Targets that do not refer to files but are just actions are called phony targets.\nVariables If a new object file is added to the system, we might add it to one list and forget the other, such duplication is error-prone. Instead, we can do this:\nobjects = main.o kbd.o command.o display.o \\ insert.o search.o files.o utils.o edit : $(objects) cc -o edit $(objects) main.o : main.c defs.h cc -c main.c kbd.o : kbd.c defs.h command.h cc -c kbd.c command.o : command.c defs.h command.h cc -c command.c display.o : display.c defs.h buffer.h cc -c display.c insert.o : insert.c defs.h buffer.h cc -c insert.c search.o : search.c defs.h buffer.h cc -c search.c files.o : files.c defs.h buffer.h command.h cc -c files.c utils.o : utils.c defs.h cc -c utils.c clean : rm edit $(objects) Other examples of using variables:\na := one two # a is assigned to the string \u0026#34;one two\u0026#34; all: printf \u0026#39;$a\u0026#39; x := dude all: echo $(x) echo ${x} Letting make Deduce the Recipes It is not necessary to spell out the recipes for compiling the individual C source files, because make can figure them out: it has an implicit rule for updating a ‘.o’ file from a correspondingly named ‘.c’ file using a ‘cc -c’ command. For example, it will use the recipe ‘cc -c main.c -o main.o’ to compile main.c into main.o. We can therefore omit the recipes from the rules for the object files.\nWhen a ‘.c’ file is used automatically in this way, …","date":1682726400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682726400,"objectID":"0d2ed62a94a6dcef9e4b04b45a393774","permalink":"http://yaoxu.github.io/post/makefile/","publishdate":"2023-04-29T00:00:00Z","relpermalink":"/post/makefile/","section":"post","summary":"Learning notes about make","tags":["Academic","Learning notes"],"title":"About Make","type":"post"},{"authors":["Yao (John) Xu"],"categories":null,"content":" Create your slides in Markdown - click the Slides button to check out the example. Supplementary notes can be added here, including code, math, and images.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554595200,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"http://yaoxu.github.io/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"http://yaoxu.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"e8f8d235e8e7f2efd912bfe865363fc3","permalink":"http://yaoxu.github.io/project/example/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/example/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Example Project","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"http://yaoxu.github.io/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":["Yao (John) Xu","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Create your slides in Markdown - click the Slides button to check out the example. Supplementary notes can be added here, including code, math, and images.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"http://yaoxu.github.io/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"},{"authors":["Yao (John) Xu","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Create your slides in Markdown - click the Slides button to check out the example. Supplementary notes can be added here, including code, math, and images.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"http://yaoxu.github.io/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"An example conference paper","type":"publication"}]