<!DOCTYPE html>
<!-- This site was created with Wowchemy. https://www.wowchemy.com -->
<!-- Last Published: June 10, 2023 --><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.7.0 for Hugo" />
  

  
  












  
  










  







  
  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  

  
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.16f785cdb553c8c4431db6775122af35.css" media="print" onload="this.media='all'">

  
  
  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css" integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    
    
    
    
      
      
    
    
    

    
    
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      
        
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.0f229d4b7ebad1917a9a357cba2effab.css" />

  
  
  

  
  
  
  
  
  
  
    
    
    <link rel="stylesheet" href="/css/libs/chroma/github-light.min.css" title="hl-light" media="print" onload="this.media='all'" >
    <link rel="stylesheet" href="/css/libs/chroma/dracula.min.css" title="hl-dark" media="print" onload="this.media='all'" disabled>
  

  
  


























  
  
  






  <meta name="author" content="Yao (John) Xu" />





  

<meta name="description" content="CMU 15-618 Parallel Computer Architecture and Programming final project" />



<link rel="alternate" hreflang="en-us" href="http://yaogh-code.github.io/post/uthread/" />
<link rel="canonical" href="http://yaogh-code.github.io/post/uthread/" />



  <link rel="manifest" href="/manifest.webmanifest" />



<link rel="icon" type="image/png" href="/media/icon_hu3fa31baf23334842a6c8f8d4ce717078_16335_32x32_fill_lanczos_center_3.png" />
<link rel="apple-touch-icon" type="image/png" href="/media/icon_hu3fa31baf23334842a6c8f8d4ce717078_16335_180x180_fill_lanczos_center_3.png" />

<meta name="theme-color" content="#1565c0" />










  






<meta property="twitter:card" content="summary_large_image" />

  <meta property="twitter:site" content="@wowchemy" />
  <meta property="twitter:creator" content="@wowchemy" />
<meta property="twitter:image" content="http://yaogh-code.github.io/post/uthread/featured.png" />
<meta property="og:site_name" content="Yao Xu" />
<meta property="og:url" content="http://yaogh-code.github.io/post/uthread/" />
<meta property="og:title" content="A Preemptive User-Level Thread Library | Yao Xu" />
<meta property="og:description" content="CMU 15-618 Parallel Computer Architecture and Programming final project" /><meta property="og:image" content="http://yaogh-code.github.io/post/uthread/featured.png" /><meta property="og:locale" content="en-us" />

  
    <meta
      property="article:published_time"
      content="2023-05-01T00:00:00&#43;00:00"
    />
  
  
    <meta property="article:modified_time" content="2023-05-01T00:00:00&#43;00:00">
  






    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://yaogh-code.github.io/post/uthread/"
  },
  "headline": "A Preemptive User-Level Thread Library",
  
  "image": [
    "http://yaogh-code.github.io/post/uthread/featured.png"
  ],
  
  "datePublished": "2023-05-01T00:00:00Z",
  "dateModified": "2023-05-01T00:00:00Z",
  
  "author": {
    "@type": "Person",
    "name": "Yao (John) Xu"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Yao Xu",
    "logo": {
      "@type": "ImageObject",
      "url": "http://yaogh-code.github.io/media/icon_hu3fa31baf23334842a6c8f8d4ce717078_16335_192x192_fill_lanczos_center_3.png"
    }
  },
  "description": "CMU 15-618 Parallel Computer Architecture and Programming final project"
}
</script>

  

  




  
  
  

  
  

  


  
  <title>A Preemptive User-Level Thread Library | Yao Xu</title>

  
  
  
  











</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="8b3621a7d9b5f8e4e83360edae723b4f" >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.ec9d49ca50e4b80bdb08f0417a28ed84.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header header--fixed">
  
  
  
  
  












<header>
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/">Yao Xu</a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/">Yao Xu</a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#about"><span>Home</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#accomplishments"><span>Courses</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#skills"><span>Skills</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#experiences"><span>Experience</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#projects"><span>Projects</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        
          
        

        
        
        
        <li class="nav-item">
          <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        
        
        
        <li class="nav-item dropdown theme-dropdown">
          <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
            <i class="fas fa-moon" aria-hidden="true"></i>
          </a>
          <div class="dropdown-menu">
            <a href="#" class="dropdown-item js-set-theme-light">
              <span>Light</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-dark">
              <span>Dark</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-auto">
              <span>Automatic</span>
            </a>
          </div>
        </li>
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    <article class="article">

  













  

  
  
  
<div class="article-container pt-3">
  <h1>A Preemptive User-Level Thread Library</h1>

  
  <p class="page-subtitle">CMU 15-618 Parallel Computer Architecture and Programming</p>
  

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span class="author-highlighted">
      Yao (John) Xu</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    May 1, 2023
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    1 min read
  </span>
  

  
  
  
  

  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder mr-1"></i><a href="/category/operating-system/">Operating System</a>, <a href="/category/parallel-computing/">Parallel Computing</a></span>
  

</div>

    





  
</div>



  <div class="article-container">

    <div class="article-style">
      <h2 id="repo-link">Repo Link</h2>
<!-- https://github.com/YaoGH-code/uthread -->
<h2 id="overview">Overview</h2>
<p>This project aims to provide a robust preemptive user-level thread library that simplifies the creation and management of user-level threads. By utilizing interfaces such as &ldquo;uthread_create&rdquo; and &ldquo;uthread_join,&rdquo; users familiar with POSIX threads can easily develop programs with user-level parallelism. The context of user-level threads in this project is implemented through a combination of our custom &ldquo;uthread&rdquo; data structure and the &ldquo;ucontext&rdquo; functionality provided by POSIX. Additionally, a lock-free data structure is employed to maintain each worker thread efficiently. The scheduling of user threads relies heavily on signals in this project. When a signal arrives, it indicates the start of the next scheduling round for each worker thread. The stack prepared by the kernel for the signal handler is crucial for smooth context switching. To ensure thread safety at the user level, interfaces such as &ldquo;umalloc,&rdquo; &ldquo;uprintf,&rdquo; and &ldquo;uthread_mutex_lock&rdquo; are provided. These interfaces facilitate safe memory allocation, printing, and mutual exclusion. This thread library is compatible with machines running MacOS or Linux with x86 architecture CPUs. Extensive testing has been conducted to verify the correctness and scalability of the system.</p>
<!-- 
## Background
With the increasing prevalence of multi-core processors, high-performance computing demands, scalability requirements, user expectations for responsiveness, and cost-efficiency considerations, concurrent programming has become increasingly essential. To achieve concurrency, multi-threading has emerged as a popular approach, primarily due to its ability to leverage the shared memory model and its lower resource consumption. POSIX threads (pthreads) have gained widespread adoption for multi-threading implementations due to their efficiency, scalability, reliability, and broad support across various operating systems. However, effectively harnessing pthreads for efficient concurrency still presents significant challenges.

One challenge arises when the number of concurrent tasks increases, potentially causing significant scheduling overhead and overwhelming hardware resources. The thread pool technique has long been used to address this issue, where it abstracts each concurrent task into a unit of work and adds it to a shared work queue. From this queue, threads in the pool grab one unit of work and finish executing it, then proceed to the next until the queue is empty. The thread pool can be a neat solution to deal with a huge quantity of tasks while keeping the scheduling overhead bounded. However, it may be insufficient when the running spans of each concurrent task are highly variable. This is especially true if we aim to achieve user-level multitasking, where we can have long-running or persistent tasks. The thread pool may not be a wise solution here, as the tasks that run much longer than the others can cause drastic delay to those far down in the queue, which, in the worst case, may never be executed. That’s because in the thread pool model subsequent tasks are not executed until all preceding tasks have been completed. If we were still to use pthreads naively, we would end up spawning hundreds of threads again, one for each task, producing immense overhead and hurting performance.

Clearly, the thread pool model should be preserved. But how to break the execution of long-running blocking tasks without compromising correctness to allow other tasks to run? To answer this question, we must introduce the idea of user-level threads. In this project, we turn each unit of work in the work queue into an execution context. Each worker thread (POSIX thread) has a task queue stores user level tasks that assigned to it when user create a user level thread with uthread create. These user level tasks are structures where we turn each unit of work in the work queue (we are still sticking to the thread pool model) into an execution context, keeping track of the full state of each concurrently running task, and instead of mapping one task to one dedicated POSIX thread, we dynamically decide which POSIX thread in the pool should execute which task, so that we can safely break the execution of one task, saving its context back to the shared queue, and start the execution of the next user-level thread, loading the corresponding context from the queue.

## Approach
Before going into the core part of this project, some initialization and helper function will be introduced first. This user level thread library requires some initialization before starting to create and schedule user level threads. The runtime start function shown below is the first function will be called to initialize a structure called runtime which is defined in uthread.c file that contains some run time information. First, there will be only one thread enter this function. We record this main thread as the master worker thread (pthread) and mark the start flag to one so that the runtime will only be initialized once. Then, in the for loop below, as many worker threads (pthread) as there are CPU cores will be created. From a perspective of the user level thread library, these worker threads are managed by struct worker. There are three important data structure associated with each worker thread which are ID, pthread id and a linked list contains struct uthread. ID is a number from 0 to number of cores - 1 which is assigned when creating the worker thread. pthread id is just a pthread t type number which returned when pthread create function is called. The linked list contains structures (struct uthread) that describes each user level thread assigned to this worker. How user level thread is defined and implemented in this library will covered later in much more details. (line 1-line 28) After initializing the run time structure and all worker threads, we installed two signal handlers for SIGALRM 3 and SIGUSR1 for worker threads. SIGALRM combined with SIGUSR1 is acting as a timer which is used to notify worker threads to schedule a new user level thread from its linked list. (line 31-line 58)
```C
void runtime_start() {
    runtime.master = pthread_self();
    runtime.started = 1;

    // get core count
    runtime.worker_count = (uint32_t)sysconf(_SC_NPROCESSORS_ONLN);

    // start as many works as cores
    // allocate memory for workers
    runtime.workers = _umalloc(sizeof(struct worker) * runtime.worker_count);
    // initialize workers
    for (int id = 0 ; id < runtime.worker_count; id++) {
        struct worker *w = &runtime.workers[id];
        // install worker id
        w->id = id;
        // initialize the work queue
        // create a dummy uthread that will stay as the head of the work queue
        w->head = _umalloc(sizeof(struct uthread));
        // initialize the dummy uthread
        // this dummny uthread does not have an id and will never be exposed to the user
        w->head->next = w->head; // circular queue
        memset(&w->head->ucon, 0 , sizeof(ucontext_t));
        // set the dummy uthread as the current thread in execution
        w->head->state = USTATE_RUNNING;
        w->cur = w->head;
        // start the pthread
        pthread_create(&w->pthread_id, NULL, dummy, (void *)(uint64_t)id);
    }

    // install signal handlers
    struct sigaction sa_alrm, sa_usr1;

    memset(&sa_alrm, 0, sizeof(sa_alrm));
    memset(&sa_usr1, 0, sizeof(sa_usr1));
    
    sa_usr1.sa_flags = SA_SIGINFO | SA_RESTART;
    sa_usr1.sa_sigaction = scheduler;
    sigfillset(&sa_usr1.sa_mask);
    sigaction(SIGUSR1, &sa_usr1, NULL);

    sa_alrm.sa_flags = SA_RESTART;
    sa_alrm.sa_handler = sigalrm_handler;
    sigfillset(&sa_alrm.sa_mask);
    sigaction(SIGALRM, &sa_alrm, NULL);

    // create a periodic timer
    struct itimerval timer;

#define MS (1000)
    // Configure the timer to fire every 10ms
    timer.it_value.tv_sec = 0;
    timer.it_value.tv_usec = MS * 10;
    timer.it_interval.tv_sec = 0;
    timer.it_interval.tv_usec = MS * 10;

    // start the timer
    while (runtime.ready_count != runtime.worker_count);
    setitimer(ITIMER_REAL, &timer, NULL);
}
```

Following function sigalrm handler defined in uthread.c described how these two signals are used in terms
of scheduling user level threads. SIGALRM is generated by the OS based on the scheduling round period
we defined when setting the timer. Since the OS will send the SIGALRM to a random worker thread that
is running in the current process context and we want all worker threads to know they should schedule the
next user level thread, the thread receives SIGALRM will send a SIGALRM signal to the master worker
thread and this master worker thread will send SIGUSR1 to each of other worker threads to notify them a
new scheduling round comes.

```C
void sigalrm_handler(int signum) {
    if (pthread_self() != runtime.master) { // not master
        pthread_kill(runtime.master, SIGALRM); // forward SIGALRM to the master thread
    } else {
        // bcast SIGUSR1 to all workers to start the scheduler
        for (int i = 0; i < runtime.worker_count; i++) {
            pthread_kill(runtime.workers[i].pthread_id, SIGUSR1);
        }
    }
}
```

The second signal handler which is used to process SIGUSR1 is registered as a function called scheduler. Back to runtime start function, this signal handler is installed by sigaction with a flag called
SA SIGINFO. When the SA SIGINFO flag is specified in act.sa flags, the signal handler address is passed
via the act.sa sigaction field. This handler takes three arguments, as follows:
* <span style="color:orange">sig</span>: The number of the signal that caused invocation of the handler.
* <span style="color:orange">info</span>: A pointer to a siginfo t, which is a structure containing further information about the signal, as described below.
* <span style="color:orange">ucontext</span>: This is a pointer to a ucontext t structure, cast to void *. The structure pointed to by this field contains signal context information that was saved on the user-space stack by the kernel.

This is why our SIGUSR1 handler (scheduler) has three arguments and the third argument is very important because of the following reason:
![Image alt](sighand.png)

The above graph shows the core process of user level scheduling. First, ”UC” stands for ”user level thread context”.

```C
struct uthread {
    int id;
    int state;
    char *stack;
    void *retptr;
    void *aux_rsp;
    char *aux_stack;
    ucontext_t ucon;
    struct uthread *next;
};
```
User level thread context is maintained with a structure called struct uthread defined in uthread.c. Each user level thread has its own ID, state, stack, a ucontext t struct and a pointer to the next struct uthread in the current queue. ucontext t is a structure defined by POSIX used to save context including general purpose register and SIMD registers etc. Back to the above graph, when a worker thread received SIGUSR1, the operating system will push three inputs for the signal handler onto its stack which can be used within the signal handler. The third one is the new user level context that was running on CPU. It will be casted to a ucontext t type variable and saved back to the user level thread context queue bu the scheduler. It will also push the next scheduled user level thread context to the stack to replace the user level thread context pushed by the OS. When signal handler returns, a system call called sigreturn will store the new context
back to CPU and continue execuation, and user level context switch is achieved.

Two interfaces most related to users are uthread_create and uthread_join. The following chunk of code is the implementation of the uthread_create function. For each newly created user level thread, a stack is allocated on the heap for later execution. The execution context will also be prepared by setting RSP to newly allocated stack, setting RDI to input and setting RIP to the function that user would run. On Linux, code segment register and stack segment register are also need to be set manually since Linux will restore context to CPU with value specified in the ucontext_t structure including CS and SS register. On Linux, there is a mcontext_t structure defined inside of the ucontext_t structure under usr/include/x86_64-linux-gnu/sys/ucontext.h. This structure defines all registers that can be managed by using ucontext. User can access or change REG CSGSFS to manage CS and SS register. However, there is a invisible padding inside of this field to user which took us a while to figure out how to store CS and SS register. Unlike Linux, MacOS manage CS and SS register automatically.

Finally, a round robin algorithm is used to assign new user context to work thread. A lock free operation is used to add newly created user level context after the first element in a worker’s queue by using _cas function defined in asm.s.

```C

#define UTHREAD_STACK_SIZE (1024 * 1024 * 8)
#define UTHREAD_SCRATCH_SPACE_SIZE (1024 * 4)
void uthread_create(uthread_t *id, void *(*func)(void *), void *arg) {

    if (!runtime.started)
        runtime_start();

    struct uthread *u = _umalloc(sizeof(struct uthread));
    memset(&u->ucon, 0, sizeof(ucontext_t));
    // assign id
    u->id = runtime.next_uid++;

    // allcoate stack on heap
    u->stack = _umalloc(UTHREAD_STACK_SIZE);
    // initailze the stack
    uint64_t *rsp = (uint64_t *)(ALIGN16(u->stack + UTHREAD_STACK_SIZE) - 8);
    // prepare the return address
    *rsp = (uint64_t)cleanup;

    // allocate the aux stack
    u->aux_stack = _umalloc(UTHREAD_SCRATCH_SPACE_SIZE);
    // initailize the aux stack
    u->aux_rsp = (void *)(ALIGN16(u->aux_stack + UTHREAD_SCRATCH_SPACE_SIZE)); // do not subtract 8 here

    // initialize the execution context
    u->ucon.uc_mcontext.gregs[REG_RSP] = (greg_t)rsp;
    u->ucon.uc_mcontext.gregs[REG_RDI] = (greg_t)arg;
    u->ucon.uc_mcontext.gregs[REG_RIP] = (greg_t)func;
    u->ucon.uc_mcontext.gregs[REG_CSGSFS] = _cs() | ((uint64_t)_ss() << 48);

    // initialize the state
    u->state = USTATE_SLEEPING;

    // pick a worker and insert the uthread into ist work queue
    struct worker *w = &runtime.workers[runtime.next_worker++ % runtime.worker_count];
    struct uthread *head = w->head;
    // add to the work queue (always add after the head)
    struct uthread *old_next;
    do {
        old_next = head->next; // the next uthread of the head is guaranteed to be valid
        u->next = old_next;
    } while (_cas(&head->next, (uint64_t)old_next, (uint64_t)u) != (uint64_t)old_next);

    *id = (uthread_t)u;
}
```
There are three function in this library are about resource recycling. cleanup function is the return address after of each user level thread, it set the current user level thread to USTATE_JOINABLE. User level thread with USTATE JOINABLE won’t be recycled immediately. After uthread join is called, user level thread will be set to USTATE_JOINED.

In each worker’s queue, the dummy head is a user level context that is responsible for freeing resources. When
this user level context is scheduled, it will look for user level context that is in USTATE_JOINABLE and
USTATE_JOINED. If the uthread is in USTATE_JOINABLE, the stack will freed because the JOINABLE
uthread cannot possibly be running since they are mapped to a single worker who’s only able to do one
thing at a time. That means the uthread will no longer be schedulable from now on because it can only be
run if the scheduler was to schedule it later, which will not happen, whereby it is safe to free its stack and
execution context. If the uthread is in USTATE_JOINED, the struct uthread will be freed since when dummy
is running, the scheduler must not be running since they again share the same worker, thus, if dummy sees
one uthread in the JOINED state, that uthread cannot be scheduled to run again, since first the scheduler is
uninterruptible, which eliminates the intermediate state being observed by dummy and second the next time
scheduler tries to schedule it will definitely also see it as JOINED and do nothing. However, one thing to
notice is that we have to make the JOINED uthread unreachable and then deallocate the memory otherwise,
when the scheduler step through it may encounter invalid memory.

![Image alt](queue.png)

The following graph shows the life cycle of a user level thread. In summary, a stack and other necessary data structures are allocated on the heap first. Then, the ucontext structure will be added into the queue of one of the workers and waiting to be scheduled. After execuation finished, it will jump to clean up function
and wait to be joined and resource recycled.

![Image alt](lifecycle.png)

Here I wish to mention a few obstacles we have met till now. Initially, we thought of implementing work queues using doubly-linked lock-free lists; however, it turned out that there had been yet no known solutions to this problem, which would not have been if a compare-and-swap instruction had been given by the architecture that can operate on two discounted addresses, and most of the articles and papers being widely accepted were just singly-linked lists. Thus, we decided to not go any further but to fall back to singly-linked lists, which did not appear to be any simpler, especially when it came to the deleting part, investigating which we got to know about the differences between lock-free and wait-free. After that, we decided to get around that, avoiding a deletion from happening in parallel with insertions or another deletions. That was achieved by constraining the insertion to only taking place between the head of the list and the second to the head. As for the deletion, we spawn another user thread during the run-time initialization that's not exposed to the user and is solely responsible for performing the deletion, and we call it the garbage collector, and an important constraint we put on this to prevent deletions and insertions from interfering each other on the second node, we forced the deletion to always start from the third node. In this way, we have a lock-free singly-linked list that can be added to in a concurrent lock-free manner. Then, when implementing uthread\_join, and uthread\_detach that involed traversing the work queue to verify the validity of a given uthread ID, we considered using the Linux RCU to better read-mostly efficiency and implemented it, but we eventually decided to revert back to having the user responsible for properly managing the IDs since the help of the RCU in our case was not conspicuously seen while it largely added to the code complexity and made the code potentially more error-prone in later stages. Then we faced the serious issue of not freeing the memory fast enough to make room for newly spawned threads, to which we came up with the solution that has each uthread free its own stack during the clean-up phase (a snippet of inline Assembly freeing the stack and saving the return value without needing a stack via using munmap syscall exploiting the fact that the syscall happens on the kernel stack).

## Results

First test (following two graphs) is using fixed amount of uthread with different number worker thread to check the scalability of this library on machines with different of number of cores. We created 4000 uthreads that each calculates Fib 30 with different number of workers. This test is done on GHC machines(CPU: i7-9700 8 cores). 
Figure 4 shows the total execution time of Fib 30 with 4000 uthreads and 1,2,3,4,5,6 and 7 workers. Figure 5 shows the linear speed up in term of doing same amount of work when we are using more workers, which meet our expectation since more workers means more execution unit available for uthreads and more concurrency, just like more cores available for pthreads. It shows the correctness of user level context switching, efficiency of the scheduling mechanism and good scalability of this library on a 8 core machine. 

![Image alt](Execution_time.png)

![Image alt](speedup.png)
The second test is using fixed amount of workers with different number of uthreads to check the scalability of this library. We created 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000 uthreads that each calculates Fib 30 based on same number of workers. This test is done on GHC machines. Figure 6 shows the execution time of Fib 30 with 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000 uthreads and 7 workers. We can see the execution time is increasing in a linear way. This means when users are creating more uthreads, the system can provide stable scheduling and performance without meeting any memory or scheduling bottleneck. In extreme case, a system with same hardware configuration as GHC machines can support 200000 uthreads running at the same time.

![Image alt](exe_time.png)


## Reference
Sundell, H., & Tsigas, P. (2008). Lock-free deques and doubly linked lists. Journal of Parallel and Distributed
Computing, 68(7), 1008–1020. https://doi.org/10.1016/j.jpdc.2008.03.001







 -->

    </div>

    





<div class="article-tags">
  
  <a class="badge badge-light" href="/tag/academic/">Academic</a>
  
  <a class="badge badge-light" href="/tag/open-source/">Open Source</a>
  
</div>



<div class="share-box">
  <ul class="share">
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=http%3A%2F%2Fyaogh-code.github.io%2Fpost%2Futhread%2F&amp;text=A&#43;Preemptive&#43;User-Level&#43;Thread&#43;Library" target="_blank" rel="noopener" class="share-btn-twitter" aria-label="twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=http%3A%2F%2Fyaogh-code.github.io%2Fpost%2Futhread%2F&amp;t=A&#43;Preemptive&#43;User-Level&#43;Thread&#43;Library" target="_blank" rel="noopener" class="share-btn-facebook" aria-label="facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
        
      
      <li>
        <a href="mailto:?subject=A%20Preemptive%20User-Level%20Thread%20Library&amp;body=http%3A%2F%2Fyaogh-code.github.io%2Fpost%2Futhread%2F" target="_blank" rel="noopener" class="share-btn-email" aria-label="envelope">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=http%3A%2F%2Fyaogh-code.github.io%2Fpost%2Futhread%2F&amp;title=A&#43;Preemptive&#43;User-Level&#43;Thread&#43;Library" target="_blank" rel="noopener" class="share-btn-linkedin" aria-label="linkedin-in">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="whatsapp://send?text=A&#43;Preemptive&#43;User-Level&#43;Thread&#43;Library%20http%3A%2F%2Fyaogh-code.github.io%2Fpost%2Futhread%2F" target="_blank" rel="noopener" class="share-btn-whatsapp" aria-label="whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=http%3A%2F%2Fyaogh-code.github.io%2Fpost%2Futhread%2F&amp;title=A&#43;Preemptive&#43;User-Level&#43;Thread&#43;Library" target="_blank" rel="noopener" class="share-btn-weibo" aria-label="weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>











  
  
    



  
  
  
    
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <a href="http://yaogh-code.github.io/"><img class="avatar mr-3 avatar-circle" src="/authors/admin/avatar_hu59ef75cf9b43e629b03a2eb6d5690fa5_817895_270x270_fill_q75_lanczos_center.jpg" alt="Yao (John) Xu"></a>
    

    <div class="media-body">
      <h5 class="card-title"><a href="http://yaogh-code.github.io/">Yao (John) Xu</a></h5>
      <h6 class="card-subtitle">Graduate student at Carnegie Mellon University</h6>
      
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
    <li>
      <a href="mailto:johnx9566@gmail.com" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/YaoGH-code" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.linkedin.com/in/johnnyyxu" target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="/uploads/resume.pdf" >
        <i class="ai ai-cv"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>


  
















  </div>
</article>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  












  
  
  
  
  













  
  
  

  
  
    
  
  
    
  

  

  
  <p class="powered-by copyright-license-text">
    © {2023} Yao Xu
  </p>
  

  <p class="powered-by footer-license-icons">
    <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank" aria-label="Creative Commons">
      <i class="fab fa-creative-commons fa-2x" aria-hidden="true"></i>
      <i class="fab fa-creative-commons-by fa-2x" aria-hidden="true"></i>
      
        <i class="fab fa-creative-commons-nc fa-2x" aria-hidden="true"></i>
      
      
        <i class="fab fa-creative-commons-nd fa-2x" aria-hidden="true"></i>
      
    </a>
  </p>





  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a> — the free, <a href="https://github.com/wowchemy/wowchemy-hugo-themes" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

  


<script src="/js/vendor-bundle.min.d26509351aa0ff874abbee824e982e9b.js"></script>




  

  
  

  













  
  <script id="search-hit-fuse-template" type="text/x-template">
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script>
  
    <script src="https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
  












  
  
  
  
  
  
  







<script id="page-data" type="application/json">{"use_headroom":true}</script>



  <script src="/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js" type="module"></script>









  
  


<script src="/en/js/wowchemy.min.e8ee06ba8371980ffde659871dd593b0.js"></script>







  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        
        <pre><code></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>


  <script src="/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js" type="module"></script>


















</body>
</html>
