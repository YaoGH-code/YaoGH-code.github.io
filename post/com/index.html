<!DOCTYPE html>
<!-- This site was created with Wowchemy. https://www.wowchemy.com -->
<!-- Last Published: January 4, 2024 --><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.7.0 for Hugo" />
  

  
  












  
  










  







  
  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  

  
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.16f785cdb553c8c4431db6775122af35.css" media="print" onload="this.media='all'">

  
  
  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css" integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    
    
    
    
      
      
    
    
    

    
    
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      
        
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.0f229d4b7ebad1917a9a357cba2effab.css" />

  
  
  

  
  
  
  
  
  
  
    
    
    <link rel="stylesheet" href="/css/libs/chroma/github-light.min.css" title="hl-light" media="print" onload="this.media='all'" >
    <link rel="stylesheet" href="/css/libs/chroma/dracula.min.css" title="hl-dark" media="print" onload="this.media='all'" disabled>
  

  
  


























  
  
  






  <meta name="author" content="Yao (John) Xu" />





  

<meta name="description" content="Learning notes about parallel programming technologies" />



<link rel="alternate" hreflang="en-us" href="https://example.com/post/com/" />
<link rel="canonical" href="https://example.com/post/com/" />



  <link rel="manifest" href="/manifest.webmanifest" />



<link rel="icon" type="image/png" href="/media/icon_hu3fa31baf23334842a6c8f8d4ce717078_16335_32x32_fill_lanczos_center_3.png" />
<link rel="apple-touch-icon" type="image/png" href="/media/icon_hu3fa31baf23334842a6c8f8d4ce717078_16335_180x180_fill_lanczos_center_3.png" />

<meta name="theme-color" content="#1565c0" />










  






<meta property="twitter:card" content="summary_large_image" />

  <meta property="twitter:site" content="@wowchemy" />
  <meta property="twitter:creator" content="@wowchemy" />
<meta property="twitter:image" content="https://example.com/post/com/featured.png" />
<meta property="og:site_name" content="Yao Xu" />
<meta property="og:url" content="https://example.com/post/com/" />
<meta property="og:title" content="POSIX threads, CUDA, OpenMP and MPI | Yao Xu" />
<meta property="og:description" content="Learning notes about parallel programming technologies" /><meta property="og:image" content="https://example.com/post/com/featured.png" /><meta property="og:locale" content="en-us" />

  
    <meta
      property="article:published_time"
      content="2023-05-30T00:00:00&#43;00:00"
    />
  
  
    <meta property="article:modified_time" content="2023-05-30T00:00:00&#43;00:00">
  






    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://example.com/post/com/"
  },
  "headline": "POSIX threads, CUDA, OpenMP and MPI",
  
  "image": [
    "https://example.com/post/com/featured.png"
  ],
  
  "datePublished": "2023-05-30T00:00:00Z",
  "dateModified": "2023-05-30T00:00:00Z",
  
  "author": {
    "@type": "Person",
    "name": "Yao (John) Xu"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Yao Xu",
    "logo": {
      "@type": "ImageObject",
      "url": "https://example.com/media/icon_hu3fa31baf23334842a6c8f8d4ce717078_16335_192x192_fill_lanczos_center_3.png"
    }
  },
  "description": "Learning notes about parallel programming technologies"
}
</script>

  

  




  
  
  

  
  

  


  
  <title>POSIX threads, CUDA, OpenMP and MPI | Yao Xu</title>

  
  
  
  











</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="af254c5828af54b7546b35540d6b027b" >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.ec9d49ca50e4b80bdb08f0417a28ed84.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header header--fixed">
  
  
  
  
  












<header>
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/">Yao Xu</a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/">Yao Xu</a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#about"><span>Home</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#skills"><span>Skills</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#accomplishments"><span>Courses</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#experiences"><span>Experience</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#projects"><span>Projects</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        
          
        

        
        
        
        <li class="nav-item">
          <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        
        
        
        <li class="nav-item dropdown theme-dropdown">
          <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
            <i class="fas fa-moon" aria-hidden="true"></i>
          </a>
          <div class="dropdown-menu">
            <a href="#" class="dropdown-item js-set-theme-light">
              <span>Light</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-dark">
              <span>Dark</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-auto">
              <span>Automatic</span>
            </a>
          </div>
        </li>
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    <article class="article">

  













  

  
  
  
<div class="article-container pt-3">
  <h1>POSIX threads, CUDA, OpenMP and MPI</h1>

  
  <p class="page-subtitle">Learning notes about parallel programming technologies</p>
  

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span class="author-highlighted">
      Yao (John) Xu</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    May 30, 2023
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    12 min read
  </span>
  

  
  
  
  

  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder mr-1"></i><a href="/category/learning-notes/">Learning notes</a></span>
  

</div>

    





  
</div>



  <div class="article-container">

    <div class="article-style">
      <h1 id="posix-threads">POSIX threads</h1>
<p>Pthreads (POSIX Threads) is a standard interface for manipulating threads in C programs. It provides a set of around 60 functions that allow developers to create, manage, and synchronize threads.</p>
<p>Threads in Pthreads run thread routines, which are defined as functions with the following signature:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="line"><span class="cl"><span class="kt">void</span> <span class="o">*</span><span class="nf">threadroutine</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">vargp</span><span class="p">);</span>
</span></span></code></pre></div><p>Some of the key functions provided by Pthreads include:</p>
<ul>
<li>
<p>Creating and reaping threads:</p>
<ul>
<li><code>pthread_create(pthread_t *tid, ..., func *f, void *arg)</code>: Creates a new thread that executes the function <code>f</code> with the argument <code>arg</code>.</li>
<li><code>pthread_join(pthread_t tid, void **thread_return)</code>: Waits for the thread with the specified thread ID (<code>tid</code>) to terminate and retrieves its exit status.</li>
</ul>
</li>
<li>
<p>Determining the thread ID:</p>
<ul>
<li><code>pthread_self()</code>: Returns the thread ID of the calling thread.</li>
</ul>
</li>
<li>
<p>Terminating threads:</p>
<ul>
<li><code>pthread_cancel(pthread_t tid)</code>: Requests cancellation of the thread with the specified thread ID (<code>tid</code>).</li>
<li><code>pthread_exit(void *thread_return)</code>: Terminates the calling thread and returns a value to the joining thread.</li>
<li>Using <code>return</code> in the primary thread routine also terminates the thread.</li>
<li>Note that calling <code>exit()</code> will terminate all threads in the process.</li>
</ul>
</li>
<li>
<p>Synchronizing access to shared variables:</p>
<ul>
<li>Pthreads provides synchronization primitives such as mutexes, condition variables, and barriers to coordinate access to shared variables and ensure thread safety. Functions like <code>pthread_mutex_init</code>, <code>pthread_mutex_lock</code>, <code>pthread_mutex_unlock</code>, <code>pthread_cond_init</code>, <code>pthread_cond_wait</code>, <code>pthread_cond_signal</code>, etc., are used for synchronization purposes.</li>
</ul>
</li>
</ul>
<h3 id="classic-problems">Classic Problems</h3>
<ol>
<li>Producer-consumer problem</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-C" data-lang="C"><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&lt;pthread.h&gt;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&lt;semaphore.h&gt;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp"></span>
</span></span><span class="line"><span class="cl"><span class="kt">sem_t</span> <span class="n">empty</span><span class="p">,</span> <span class="n">full</span><span class="p">;</span>           <span class="c1">// Define global semaphores empty and full
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="kt">pthread_mutex_t</span> <span class="n">mutex</span><span class="p">;</span>       <span class="c1">// Define a global mutex for different functions
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="kt">int</span> <span class="n">buffer_count</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>        <span class="c1">// Define a global variable to represent the number of products in the buffer
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl"><span class="kt">void</span> <span class="o">*</span><span class="nf">producer</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">arg</span><span class="p">);</span>   <span class="c1">// Producer thread
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="kt">void</span> <span class="o">*</span><span class="nf">consumer</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">arg</span><span class="p">);</span>   <span class="c1">// Consumer thread
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl"><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">*</span><span class="n">argv</span><span class="p">[])</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">pthread_t</span> <span class="n">thrd_prod</span><span class="p">,</span> <span class="n">thrd_cons</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="nf">pthread_mutex_init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mutex</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">);</span>    <span class="c1">// Initialize the mutex
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="nf">sem_init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">empty</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">);</span>              <span class="c1">// Initialize the empty semaphore
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="nf">sem_init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">full</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>               <span class="c1">// Initialize the full semaphore
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">    <span class="c1">// Create producer and consumer threads
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">if</span> <span class="p">(</span><span class="nf">pthread_create</span><span class="p">(</span><span class="o">&amp;</span><span class="n">thrd_prod</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">,</span> <span class="n">producer</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="nf">printf</span><span class="p">(</span><span class="s">&#34;Thread creation failed.&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="nf">pthread_create</span><span class="p">(</span><span class="o">&amp;</span><span class="n">thrd_cons</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">,</span> <span class="n">consumer</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="nf">printf</span><span class="p">(</span><span class="s">&#34;Thread creation failed.&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">// Wait for threads to finish
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">if</span> <span class="p">(</span><span class="nf">pthread_join</span><span class="p">(</span><span class="n">thrd_prod</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="nf">printf</span><span class="p">(</span><span class="s">&#34;Waiting for thread failed.&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="nf">pthread_join</span><span class="p">(</span><span class="n">thrd_cons</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="nf">printf</span><span class="p">(</span><span class="s">&#34;Waiting for thread failed.&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="nf">sem_destroy</span><span class="p">(</span><span class="o">&amp;</span><span class="n">full</span><span class="p">);</span>                <span class="c1">// Release the semaphore
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="nf">sem_destroy</span><span class="p">(</span><span class="o">&amp;</span><span class="n">empty</span><span class="p">);</span>               <span class="c1">// Release the semaphore
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="nf">pthread_mutex_destroy</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mutex</span><span class="p">);</span>     <span class="c1">// Destroy the mutex
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">void</span> <span class="o">*</span><span class="nf">producer</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">arg</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">while</span> <span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="nf">sem_wait</span><span class="p">(</span><span class="o">&amp;</span><span class="n">empty</span><span class="p">);</span>               <span class="c1">// empty-1
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="nf">pthread_mutex_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mutex</span><span class="p">);</span>     <span class="c1">// Lock the mutex
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">        <span class="c1">// Successfully acquired the mutex, now can perform production
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="nf">printf</span><span class="p">(</span><span class="s">&#34;Producer puts a product in the buffer.&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">buffer_count</span><span class="o">++</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="nf">printf</span><span class="p">(</span><span class="s">&#34;The buffer count is %d</span><span class="se">\n</span><span class="s">&#34;</span><span class="p">,</span> <span class="n">buffer_count</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="nf">pthread_mutex_unlock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mutex</span><span class="p">);</span>   <span class="c1">// Unlock the mutex
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="nf">sem_post</span><span class="p">(</span><span class="o">&amp;</span><span class="n">full</span><span class="p">);</span>                 <span class="c1">// full+1
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">void</span> <span class="o">*</span><span class="nf">consumer</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">arg</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">while</span> <span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="nf">sem_wait</span><span class="p">(</span><span class="o">&amp;</span><span class="n">full</span><span class="p">);</span>                <span class="c1">// full-1
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="nf">pthread_mutex_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mutex</span><span class="p">);</span>     <span class="c1">// Lock the mutex
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">        <span class="c1">// Successfully acquired the mutex, now can perform consumption
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="nf">printf</span><span class="p">(</span><span class="s">&#34;Consumer gets a product from the buffer.&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">buffer_count</span><span class="o">--</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="nf">printf</span><span class="p">(</span><span class="s">&#34;The buffer count is %d</span><span class="se">\n</span><span class="s">&#34;</span><span class="p">,</span> <span class="n">buffer_count</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="nf">pthread_mutex_unlock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mutex</span><span class="p">);</span>   <span class="c1">// Unlock the mutex
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="nf">sem_post</span><span class="p">(</span><span class="o">&amp;</span><span class="n">empty</span><span class="p">);</span>                <span class="c1">// empty+1
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><ol start="2">
<li>Readers–writers problem</li>
</ol>
<p>The first readers-writers problem, which favors readers, can be summarized with the following conditions:</p>
<ol>
<li>No reader should be kept waiting unless a writer has already been granted permission to use the shared object.</li>
<li>If a writer is already waiting, a reader that arrives should be given priority over the writer.</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-C" data-lang="C"><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&lt;pthread.h&gt;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&lt;semaphore.h&gt;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp"></span><span class="kt">sem_t</span> <span class="n">wrt</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="kt">pthread_mutex_t</span> <span class="n">mutex</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="kt">int</span> <span class="n">cnt</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="kt">int</span> <span class="n">numreader</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">void</span> <span class="o">*</span><span class="nf">writer</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">wno</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>   
</span></span><span class="line"><span class="cl">    <span class="nf">sem_wait</span><span class="p">(</span><span class="o">&amp;</span><span class="n">wrt</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">cnt</span> <span class="o">=</span> <span class="n">cnt</span><span class="o">*</span><span class="mi">2</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="nf">printf</span><span class="p">(</span><span class="s">&#34;Writer %d modified cnt to %d</span><span class="se">\n</span><span class="s">&#34;</span><span class="p">,(</span><span class="o">*</span><span class="p">((</span><span class="kt">int</span> <span class="o">*</span><span class="p">)</span><span class="n">wno</span><span class="p">)),</span><span class="n">cnt</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="nf">sem_post</span><span class="p">(</span><span class="o">&amp;</span><span class="n">wrt</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="kt">void</span> <span class="o">*</span><span class="nf">reader</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">rno</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>   
</span></span><span class="line"><span class="cl">    <span class="c1">// Reader acquire the lock before modifying numreader
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="nf">pthread_mutex_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mutex</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">numreader</span><span class="o">++</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span><span class="p">(</span><span class="n">numreader</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="nf">sem_wait</span><span class="p">(</span><span class="o">&amp;</span><span class="n">wrt</span><span class="p">);</span> <span class="c1">// If this id the first reader, then it will block the writer
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="nf">pthread_mutex_unlock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mutex</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// Reading Section
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="nf">printf</span><span class="p">(</span><span class="s">&#34;Reader %d: read cnt as %d</span><span class="se">\n</span><span class="s">&#34;</span><span class="p">,</span><span class="o">*</span><span class="p">((</span><span class="kt">int</span> <span class="o">*</span><span class="p">)</span><span class="n">rno</span><span class="p">),</span><span class="n">cnt</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">// Reader acquire the lock before modifying numreader
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="nf">pthread_mutex_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mutex</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">numreader</span><span class="o">--</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span><span class="p">(</span><span class="n">numreader</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="nf">sem_post</span><span class="p">(</span><span class="o">&amp;</span><span class="n">wrt</span><span class="p">);</span> <span class="c1">// If this is the last reader, it will wake up the writer.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="nf">pthread_mutex_unlock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mutex</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">int</span> <span class="nf">main</span><span class="p">(){</span>   
</span></span><span class="line"><span class="cl">    <span class="kt">pthread_t</span> <span class="n">read</span><span class="p">[</span><span class="mi">10</span><span class="p">],</span><span class="n">write</span><span class="p">[</span><span class="mi">5</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">    <span class="nf">pthread_mutex_init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mutex</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="nf">sem_init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">wrt</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">a</span><span class="p">[</span><span class="mi">10</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">10</span><span class="p">};</span> <span class="c1">//Just used for numbering the producer and consumer
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">10</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="nf">pthread_create</span><span class="p">(</span><span class="o">&amp;</span><span class="n">read</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="nb">NULL</span><span class="p">,</span> <span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="p">)</span><span class="n">reader</span><span class="p">,</span> <span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="p">)</span><span class="o">&amp;</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">5</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="nf">pthread_create</span><span class="p">(</span><span class="o">&amp;</span><span class="n">write</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="nb">NULL</span><span class="p">,</span> <span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="p">)</span><span class="n">writer</span><span class="p">,</span> <span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="p">)</span><span class="o">&amp;</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">10</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="nf">pthread_join</span><span class="p">(</span><span class="n">read</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="nb">NULL</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">5</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="nf">pthread_join</span><span class="p">(</span><span class="n">write</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="nb">NULL</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="nf">pthread_mutex_destroy</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mutex</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="nf">sem_destroy</span><span class="p">(</span><span class="o">&amp;</span><span class="n">wrt</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><h1 id="cuda">CUDA</h1>
<p>In 2006, NVIDIA introduced CUDA, a general-purpose parallel computing platform and programming model designed for NVIDIA GPUs. CUDA programming enables efficient solution of complex computational problems by leveraging the parallel computing engines of GPUs. In recent years, one of the most successful applications of GPUs has been in the field of deep learning, where parallel computing on GPUs has become the standard for training deep learning models.</p>
<p>GPUs typically contain more computational cores and are particularly well-suited for data-parallel and computationally intensive tasks, such as large-scale matrix operations. On the other hand, CPUs have fewer cores but excel at executing complex logical operations, making them suitable for control-intensive tasks. Additionally, threads on CPUs are heavyweight, resulting in significant context-switching overhead. In contrast, GPUs have a large number of cores, and their threads are lightweight, enabling efficient parallel execution.</p>
<h3 id="programming-model">Programming Model</h3>
<p>In CUDA, the concepts of &ldquo;host&rdquo; and &ldquo;device&rdquo; are essential. The term &ldquo;host&rdquo; refers to the CPU and its associated memory, while &ldquo;device&rdquo; refers to the GPU and its memory. A CUDA program consists of both host and device code, which execute on the CPU and GPU, respectively. Communication between the host and device is possible, allowing for data transfers between them. The typical execution flow of a CUDA program is as follows:</p>
<ul>
<li>Allocate memory on the host and initialize data.</li>
<li>Allocate memory on the device and copy data from the host to the device.</li>
<li>Invoke CUDA kernel functions to perform specified computations on the device.</li>
<li>Copy the computation results from the device back to the host.</li>
<li>Free the allocated memory on both the device and host.</li>
</ul>
<p>Example:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&lt;cuda_runtime.h&gt;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp">#include</span> <span class="cpf">&lt;iostream&gt;</span><span class="cp">
</span></span></span><span class="line"><span class="cl"><span class="cp"></span>
</span></span><span class="line"><span class="cl"><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">VectorAddGPU</span><span class="p">(</span><span class="k">const</span> <span class="kt">float</span> <span class="o">*</span><span class="k">const</span> <span class="n">a</span><span class="p">,</span> <span class="k">const</span> <span class="kt">float</span> <span class="o">*</span><span class="k">const</span> <span class="n">b</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                             <span class="kt">float</span> <span class="o">*</span><span class="k">const</span> <span class="n">c</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">  <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">  <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">  <span class="k">const</span> <span class="n">size_t</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">10240</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="k">const</span> <span class="n">size_t</span> <span class="n">n</span> <span class="o">=</span> <span class="n">size</span> <span class="o">/</span> <span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">  <span class="kt">float</span> <span class="o">*</span><span class="n">ha</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">float</span><span class="p">[</span><span class="n">n</span><span class="p">]();</span>
</span></span><span class="line"><span class="cl">  <span class="kt">float</span> <span class="o">*</span><span class="n">hb</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">float</span><span class="p">[</span><span class="n">n</span><span class="p">]();</span>
</span></span><span class="line"><span class="cl">  <span class="kt">float</span> <span class="o">*</span><span class="n">hc</span> <span class="o">=</span> <span class="k">new</span> <span class="kt">float</span><span class="p">[</span><span class="n">n</span><span class="p">]();</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">ha</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">hb</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">size</span> <span class="o">-</span> <span class="n">i</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="kt">float</span> <span class="o">*</span><span class="n">da</span> <span class="o">=</span> <span class="k">nullptr</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="kt">float</span> <span class="o">*</span><span class="n">db</span> <span class="o">=</span> <span class="k">nullptr</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="kt">float</span> <span class="o">*</span><span class="n">dc</span> <span class="o">=</span> <span class="k">nullptr</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span> <span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">da</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">  <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span> <span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">db</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">  <span class="n">cudaMalloc</span><span class="p">((</span><span class="kt">void</span> <span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">dc</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">da</span><span class="p">,</span> <span class="n">ha</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">  <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">db</span><span class="p">,</span> <span class="n">hb</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">  <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">dc</span><span class="p">,</span> <span class="n">hc</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="k">const</span> <span class="kt">int</span> <span class="n">thread_per_block</span> <span class="o">=</span> <span class="mi">256</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="k">const</span> <span class="kt">int</span> <span class="n">block_per_grid</span> <span class="o">=</span> <span class="p">(</span><span class="n">size</span> <span class="o">+</span> <span class="n">thread_per_block</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">thread_per_block</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="n">VectorAddGPU</span><span class="o">&lt;&lt;&lt;</span><span class="n">block_per_grid</span><span class="p">,</span> <span class="n">thread_per_block</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">da</span><span class="p">,</span> <span class="n">db</span><span class="p">,</span> <span class="n">dc</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">hc</span><span class="p">,</span> <span class="n">dc</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="n">cudaFree</span><span class="p">(</span><span class="n">da</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">  <span class="n">cudaFree</span><span class="p">(</span><span class="n">db</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">  <span class="n">cudaFree</span><span class="p">(</span><span class="n">dc</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="k">delete</span><span class="p">[]</span> <span class="n">ha</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="k">delete</span><span class="p">[]</span> <span class="n">hb</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="k">delete</span><span class="p">[]</span> <span class="n">hc</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><p>In CUDA, function type qualifiers are used to differentiate between functions executed on the host and those executed on the device. The main three function type qualifiers are as follows:</p>
<ol>
<li>
<p><code>__global__</code>: Functions marked with <code>__global__</code> are executed on the device and can be called from the host. The return type must be &ldquo;void&rdquo;, variable arguments are not supported, and they cannot be member functions of a class. It&rsquo;s important to note that kernels defined with <code>__global__</code> are asynchronous, meaning that the host does not wait for the kernel to finish before proceeding to the next step.</p>
</li>
<li>
<p><code>__device__</code>: Functions marked with <code>__device__</code> are executed on the device and can only be called from other device functions.</p>
</li>
<li>
<p><code>__host__</code>: Functions marked with <code>__host__</code> are executed on the host and can only be called from the host. It can be used together with <code>__device__</code>, in which case the function is compiled for both the device and the host.</p>
</li>
</ol>
<p>On the GPU, there are many lightweight parallel threads. When a kernel is executed on the device, it actually launches multiple threads. All the threads launched by a kernel are collectively referred to as a grid. Threads within the same grid share the same global memory space. Within a grid, there are multiple thread blocks. A thread block contains numerous threads, forming the second level of the hierarchy. The organization of threads in two levels is illustrated in the diagram below, representing a 2-dimensional structure for both the grid and blocks.
















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="Image alt" srcset="
               /post/com/cuda_th_hua6a34128e5859922a44755acde970655_32723_e984c5861adbff87d4a2170bf4beec2c.webp 400w,
               /post/com/cuda_th_hua6a34128e5859922a44755acde970655_32723_2f1b3e997f94b75cd95e3a2ea28f09f6.webp 760w,
               /post/com/cuda_th_hua6a34128e5859922a44755acde970655_32723_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
               src="/post/com/cuda_th_hua6a34128e5859922a44755acde970655_32723_e984c5861adbff87d4a2170bf4beec2c.webp"
               width="562"
               height="525"
               loading="lazy" data-zoomable /></div>
  </div></figure>

Both the grid and block are defined as variables of type dim3, which can be considered as a structure variable containing three unsigned integers (x, y, z) as members. By default, when defined, they are initialized to 1.</p>
<p>Example:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="k">const</span> <span class="kt">int</span> <span class="n">Nx</span> <span class="o">=</span> <span class="mi">12</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="k">const</span> <span class="kt">int</span> <span class="n">Ny</span> <span class="o">=</span> <span class="mi">6</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">dim3</span> <span class="nf">threadsPerBlock</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">dim3</span> <span class="nf">numBlocks</span><span class="p">(</span><span class="n">Nx</span><span class="o">/</span><span class="n">threadsPerBlock</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">Ny</span><span class="o">/</span><span class="n">threadsPerBlock</span><span class="p">.</span><span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">matrixAdd</span><span class="o">&lt;&lt;&lt;</span><span class="n">numBlocks</span><span class="p">,</span> <span class="n">threadsPerBlock</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">params</span><span class="p">...,);</span>
</span></span></code></pre></div><p>For convenience, threadIdx is a 3-component vector that allows you to use one-dimensional, two-dimensional, or three-dimensional thread indices to identify threads, forming one-dimensional, two-dimensional, or three-dimensional thread blocks, respectively.
The relationship between thread indices and thread IDs is straightforward. For a one-dimensional block, they are the same. For a two-dimensional block of size (Dx, Dy), the thread ID of a thread with indices (x, y) is given by (x + y * Dx). For a three-dimensional block of size (Dx, Dy, Dz), the thread ID of a thread with indices (x, y, z) is given by (x + y * Dx + z * Dx * Dy).</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-C++" data-lang="C++"><span class="line"><span class="cl"><span class="c1">// Kernel definition
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">MatAdd</span><span class="p">(</span><span class="kt">float</span> <span class="n">A</span><span class="p">[</span><span class="n">N</span><span class="p">][</span><span class="n">N</span><span class="p">],</span> <span class="kt">float</span> <span class="n">B</span><span class="p">[</span><span class="n">N</span><span class="p">][</span><span class="n">N</span><span class="p">],</span> <span class="kt">float</span> <span class="n">C</span><span class="p">[</span><span class="n">N</span><span class="p">][</span><span class="n">N</span><span class="p">]){</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">B</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">];</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">int</span> <span class="nf">main</span><span class="p">(){</span>
</span></span><span class="line"><span class="cl">    <span class="p">...</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// Kernel invocation with one block of N * N * 1 threads
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">int</span> <span class="n">numBlocks</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">dim3</span> <span class="n">threadsPerBlock</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">N</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">MatAdd</span><span class="o">&lt;&lt;&lt;</span><span class="n">numBlocks</span><span class="p">,</span> <span class="n">threadsPerBlock</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">...</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><p>There is a limit to the number of threads per block, since all threads of a block are expected to reside on the same streaming multiprocessor core and must share the limited memory resources of that core. On current GPUs, a thread block may contain up to 1024 threads. However, a kernel can be executed by multiple equally-shaped thread blocks, so that the total number of threads is equal to the number of threads per block times the number of blocks. Blocks are organized into a one-dimensional, two-dimensional, or three-dimensional grid of thread blocks. The number of thread blocks in a grid is usually dictated by the size of the data being processed, which typically exceeds the number of processors in the system.</p>
<h3 id="memory-model">Memory Model</h3>
<p>In CUDA, there are different types of memory available for storing variables within the context of kernel execution. Here are the main memory types and their characteristics:</p>
<ol>
<li>Register Memory:</li>
</ol>
<ul>
<li>Scalar variables declared within the kernel function without any attribute are stored in register memory by default.</li>
<li>Register memory access is very fast, but the number of registers per block is limited.</li>
<li>Register variables are private to each thread within the block and have the lifetime of the thread.</li>
</ul>
<ol start="2">
<li>Local Memory:</li>
</ol>
<ul>
<li>Variables that exceed the available register space or are accessed with runtime indexes are stored in local memory.</li>
<li>Local memory has the same access latency as global memory and is not cached on all GPU architectures.</li>
<li>Local variables are private to each thread within the block and have the lifetime of the thread.</li>
</ul>
<ol start="3">
<li>Shared Memory:</li>
</ol>
<ul>
<li>Variables decorated with the <code>__shared__</code> attribute are stored in shared memory.</li>
<li>Accessing shared memory is much faster than accessing global memory, but the amount of shared memory per streaming multiprocessor is limited.</li>
<li>Shared memory is declared within the kernel function and has the lifetime of the block.</li>
<li>Shared memory can be read from and written to within the kernel, and modifications require synchronization using <code>__syncthreads()</code>.</li>
</ul>
<ol start="4">
<li>Global Memory:</li>
</ol>
<ul>
<li>Variables declared with the <code>__device__</code> attribute and declared in global scope (outside of the kernel function) are stored in global memory.</li>
<li>Global memory has high access latency compared to shared memory but provides a larger memory space.</li>
<li>Global memory can be read from and written to using <code>cudaMemcpy</code> functions.</li>
<li>Global memory has the lifetime of the application and is accessible to all threads of all kernels.</li>
</ul>
<ol start="5">
<li>Constant Memory:</li>
</ol>
<ul>
<li>Variables decorated with the <code>__constant__</code> attribute are stored in constant memory.</li>
<li>Constant memory is cached and has faster access latency than global memory.</li>
<li>Constant memory is read-only within the kernel and is typically used for storing constant data that doesn&rsquo;t change during kernel execution.</li>
<li>Constant memory can be written to by the host using <code>cudaMemcpyToSymbol</code> and read from using <code>cudaMemcpyFromSymbol</code>.</li>
</ul>
<p>















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="Image alt" srcset="
               /post/com/mem_huaf8b7816e44fdf0979208c06e34195ce_702074_b9c11c63f70b5f3f67166744ee378552.webp 400w,
               /post/com/mem_huaf8b7816e44fdf0979208c06e34195ce_702074_cb248e2372ad4bfaa77e0b48faea56b0.webp 760w,
               /post/com/mem_huaf8b7816e44fdf0979208c06e34195ce_702074_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
               src="/post/com/mem_huaf8b7816e44fdf0979208c06e34195ce_702074_b9c11c63f70b5f3f67166744ee378552.webp"
               width="760"
               height="196"
               loading="lazy" data-zoomable /></div>
  </div></figure>

Source: <a href="https://www.ce.jhu.edu/dalrymple/classes/602/Class13.pdf" target="_blank" rel="noopener">https://www.ce.jhu.edu/dalrymple/classes/602/Class13.pdf</a></p>
<h3 id="assigning-work">Assigning work</h3>
<p>NVIDIA GPU architecture is built around scalable multi-threaded Streaming Multiprocessors (SM). Each multiprocessor is designed to simultaneously execute hundreds of threads. To manage such a large number of threads, it employs a unique architecture called SIMT (Single Instruction, Multiple Thread). The multiprocessor creates, schedules, and executes threads in groups of 32 parallel threads known as warps.</p>
<p>In NVIDIA GPUs, a warp is a CUDA implementation detail that plays a crucial role in parallel execution. It refers to a group of 32 CUDA threads within a thread block that are executed simultaneously using a 32-wide SIMD (Single Instruction, Multiple Data) execution model. This means that all threads within a warp execute the same instruction at the same time, but with different data. The grouping of threads into warps is essential for efficient parallel processing. However, it&rsquo;s important to note that performance can suffer if the threads within a warp diverge, meaning they take different execution paths based on conditional statements or data dependencies. When threads in a warp diverge, the GPU has to execute each branch path separately, disabling threads that are not on that specific path. This can result in decreased performance due to serialized execution.</p>
<p>In terms of thread block organization, threads 0 to 31 belong to the same warp, while threads 32 to 63 form the next warp, and so on. Consequently, a thread block with 256 CUDA threads is divided into 8 warps, with each warp consisting of 32 threads. This warp organization allows for efficient utilization of the GPU&rsquo;s resources and facilitates synchronized execution within a block.</p>
<p>The GPU architecture, such as the &ldquo;SMM&rdquo; (Streaming Multiprocessor) core found in GPUs like the GTX 980, can schedule and interleave the execution of multiple warps. Each SMM core has the capability to concurrently execute up to 64 warps, enabling high levels of parallelism. This means that multiple CUDA thread blocks can be executed simultaneously by a single SMM core, maximizing the computational capabilities of the GPU.
















<figure  >
  <div class="d-flex justify-content-center">
    <div class="w-100" ><img alt="Image alt" srcset="
               /post/com/wrap_hu4f2aa65e0490eeddf4d794c26fb9b407_1834345_e42931f2dd5d3dd075792ef0c5d9bb31.webp 400w,
               /post/com/wrap_hu4f2aa65e0490eeddf4d794c26fb9b407_1834345_0b4465f27a693e70ba492824b45cdaf7.webp 760w,
               /post/com/wrap_hu4f2aa65e0490eeddf4d794c26fb9b407_1834345_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
               src="/post/com/wrap_hu4f2aa65e0490eeddf4d794c26fb9b407_1834345_e42931f2dd5d3dd075792ef0c5d9bb31.webp"
               width="760"
               height="572"
               loading="lazy" data-zoomable /></div>
  </div></figure>

Source: CMU 15418/618 - Parallel Computer Architecture and Programming <a href="http://15418.courses.cs.cmu.edu/spring2017/lecture/gpuarch/slide_057" target="_blank" rel="noopener">http://15418.courses.cs.cmu.edu/spring2017/lecture/gpuarch/slide_057</a></p>
<p>Taking the example of the GTX 1080, as shown in the diagram, each SM (Streaming Multiprocessor) unit within the GP104 core has 4 sets of execution units, which can be thought of as hardware threads in traditional CPUs. At any given time, an execution unit will use 32 SIMD (Single Instruction Multiple Data) units to execute the context of a warp (32 CUDA threads) in parallel.</p>

    </div>

    





<div class="article-tags">
  
  <a class="badge badge-light" href="/tag/academic/">Academic</a>
  
  <a class="badge badge-light" href="/tag/learning-notes/">Learning notes</a>
  
</div>



<div class="share-box">
  <ul class="share">
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fexample.com%2Fpost%2Fcom%2F&amp;text=POSIX&#43;threads%2C&#43;CUDA%2C&#43;OpenMP&#43;and&#43;MPI" target="_blank" rel="noopener" class="share-btn-twitter" aria-label="twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https%3A%2F%2Fexample.com%2Fpost%2Fcom%2F&amp;t=POSIX&#43;threads%2C&#43;CUDA%2C&#43;OpenMP&#43;and&#43;MPI" target="_blank" rel="noopener" class="share-btn-facebook" aria-label="facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
        
      
      <li>
        <a href="mailto:?subject=POSIX%20threads%2C%20CUDA%2C%20OpenMP%20and%20MPI&amp;body=https%3A%2F%2Fexample.com%2Fpost%2Fcom%2F" target="_blank" rel="noopener" class="share-btn-email" aria-label="envelope">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fexample.com%2Fpost%2Fcom%2F&amp;title=POSIX&#43;threads%2C&#43;CUDA%2C&#43;OpenMP&#43;and&#43;MPI" target="_blank" rel="noopener" class="share-btn-linkedin" aria-label="linkedin-in">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="whatsapp://send?text=POSIX&#43;threads%2C&#43;CUDA%2C&#43;OpenMP&#43;and&#43;MPI%20https%3A%2F%2Fexample.com%2Fpost%2Fcom%2F" target="_blank" rel="noopener" class="share-btn-whatsapp" aria-label="whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https%3A%2F%2Fexample.com%2Fpost%2Fcom%2F&amp;title=POSIX&#43;threads%2C&#43;CUDA%2C&#43;OpenMP&#43;and&#43;MPI" target="_blank" rel="noopener" class="share-btn-weibo" aria-label="weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>











  
  
    



  
  
  
    
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <a href="https://example.com/"><img class="avatar mr-3 avatar-circle" src="/authors/admin/avatar_hu59ef75cf9b43e629b03a2eb6d5690fa5_817895_270x270_fill_q75_lanczos_center.jpg" alt="Yao (John) Xu"></a>
    

    <div class="media-body">
      <h5 class="card-title"><a href="https://example.com/">Yao (John) Xu</a></h5>
      <h6 class="card-subtitle">Graduate student at Carnegie Mellon University</h6>
      
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
    <li>
      <a href="mailto:johnx9566@gmail.com" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/YaoGH-code" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.linkedin.com/in/johnnyyxu" target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="/uploads/resume2.pdf" >
        <i class="ai ai-cv"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>


  
















  </div>
</article>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  












  
  
  
  
  













  
  
  

  
  
    
  
  
    
  

  

  
  <p class="powered-by copyright-license-text">
    © {2023} Yao Xu
  </p>
  

  <p class="powered-by footer-license-icons">
    <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank" aria-label="Creative Commons">
      <i class="fab fa-creative-commons fa-2x" aria-hidden="true"></i>
      <i class="fab fa-creative-commons-by fa-2x" aria-hidden="true"></i>
      
        <i class="fab fa-creative-commons-nc fa-2x" aria-hidden="true"></i>
      
      
        <i class="fab fa-creative-commons-nd fa-2x" aria-hidden="true"></i>
      
    </a>
  </p>





  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a> — the free, <a href="https://github.com/wowchemy/wowchemy-hugo-themes" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

  


<script src="/js/vendor-bundle.min.d26509351aa0ff874abbee824e982e9b.js"></script>




  

  
  

  













  
  <script id="search-hit-fuse-template" type="text/x-template">
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script>
  
    <script src="https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
  












  
  
  
  
  
  
  







<script id="page-data" type="application/json">{"use_headroom":true}</script>



  <script src="/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js" type="module"></script>









  
  


<script src="/en/js/wowchemy.min.e8ee06ba8371980ffde659871dd593b0.js"></script>







  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        
        <pre><code></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>


  <script src="/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js" type="module"></script>


















</body>
</html>
